<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/page/3/index.html">
<meta property="og:site_name" content="Hexo">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-深入理解文件系统" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/03/30/深入理解文件系统/" class="article-date">
  <time datetime="2017-03-30T03:40:00.000Z" itemprop="datePublished">2017-03-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/03/30/深入理解文件系统/">深入理解文件系统</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h4 id="虚拟文件系统（VFS）的思想和作用"><a href="#虚拟文件系统（VFS）的思想和作用" class="headerlink" title="虚拟文件系统（VFS）的思想和作用"></a>虚拟文件系统（VFS）的思想和作用</h4><p>实际上，看到<strong>Virtaul</strong>，我们就应该想到VFS的作用，是虚拟出一个中间层，来实现某些部分的<strong>统一处理</strong>。实际上，VFS要解决的是，让应用能够“以一种通用的方式”，去访问不同类型的文件系统：<br><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/VFS.png?raw=true =100" alt=""><br>可以看到，对于不同类型的文件系统、网络文件系统、伪文件系统，应用对它们的操作接口都是一致的,而底层的驱动则会完成实际的区分工作。  </p>
<h4 id="通用文件模型"><a href="#通用文件模型" class="headerlink" title="通用文件模型"></a>通用文件模型</h4><p>VFS通过一个通用文件模型，来表示一个文件系统，它从顶层到底层，一共维护四个数据结构。这里我们通过磁盘文件系统来举例子说明：<br>file：文件<strong>对象</strong>。如果一个进程要和一个对象进行交互，那么久要在访问期间存放一个文件对象在内核内存中。<br>dentry：目录项<strong>对象</strong>。用来存放目录项和对应文件链接信息，每个磁盘文件系统，都有特殊的方式，将该类信息存在磁盘上。<br>inode：索引节点<strong>对象</strong>。用来存放关于具体文件的一般信息，对基于磁盘的文件系统来说，通常对应于存放在磁盘上的文件控制块，其节点号唯一标识文件系统中的文件。<br>superblock：超级块<strong>对象</strong>。对应安装的文件系统的信息，他对应磁盘上的文件系统控制块。</p>
<p><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E9%80%9A%E7%94%A8%E6%A8%A1%E5%9E%8B.png?raw=true ＝100" alt=""></p>
<p>这张图反映出了在一次访问中，各个对象是如何参与到过程中去的。这里我为什么要把<strong>对象</strong>给加粗呢？VFS实际采用的是一种面向对象的方式（虽然它是用C语言写的）。每个object，都有一系列的“操作方式”，VFS为这些对象提供了“统一的”接口，而具体的文件系统则提供了千差万别的实现方式，这是由一个函数指针表来实现的。  </p>
<h4 id="文件对象"><a href="#文件对象" class="headerlink" title="文件对象"></a>文件对象</h4><p>这里我们从文件对象开始说。如果留意进程的<code>task_struct</code>（定义在sched.h当中），你会发现一个<code>fs_struct</code>结构，以及一个<code>files_struct</code>结构。<br>其中<code>fs_struct</code>保存了当前点工作目录和根目录：</p>
<pre><code>struct fs_struct {
int users;
spinlock_t lock;
seqcount_t seq;
int umask;
int in_exec;
struct path root, pwd;
};
</code></pre><p>而<code>files_struct</code>结构则保存了当前进程所打开的所有文件，它们保存在<code>fdtable</code>中：</p>
<pre><code>struct fdtable {
unsigned int max_fds;
struct file __rcu **fd;      /* current fd array */
unsigned long *close_on_exec;
unsigned long *open_fds;
struct rcu_head rcu;
};
</code></pre><p>当<code>open()</code>系统调用发生时，文件描述符实际上是fd中的下标。现在我们终于看到<code>file</code>结构了，这里我只列出了重要的部分：</p>
<pre><code>struct file {
union {
    struct llist_node    fu_llist;
    struct rcu_head     fu_rcuhead;
} f_u;
struct path        f_path;
struct inode        *f_inode;    /* cached value */
const struct file_operations    *f_op;  

struct mutex        f_pos_lock;
loff_t            f_pos;

} __attribute__((aligned(4)));    
</code></pre><p>这里，<code>loff_t</code>是平时我们用来在文件读写上用于定位的指针，显然这个值必须放在file当中，因为可能会有几个进程同时访问一个文件。<br>而<code>f_op</code>正反映出了“通用文件模型的”特点，它保存了文件操作的对应指针；这个值是在进程打开文件时，从文件索引节点中的i_fop中复制的。<br>当然在<code>file</code>中我们也看到了<code>dentry</code>和<code>inode</code>的影子：<code>f_path</code>包含了<code>dentry *</code>，而*f_indoe也是file的一个域，它们分别指向了对应文件点dentry对象和inode对象，我们将会在接下来对它们进行详细的说明。  </p>
<h4 id="目录项对象"><a href="#目录项对象" class="headerlink" title="目录项对象"></a>目录项对象</h4><p>在上一节中，我们知道了文件对象描述了应用和文件的联系。这里，目录项是用来描述具体的文件系统中的目录项的，他的作用是：<strong>用来快速找到一个路径，并且与文件相关联</strong>。假设进程需要查找一个路径，那么路径中的每一个分量，都会有一个目录项与之对应。并且，目录项会把每个分量和它对应的索引节点联系起来。<code>dentry</code>的定义如下：  </p>
<pre><code>struct dentry {
unsigned int d_flags;        
seqcount_t d_seq;        
struct hlist_bl_node d_hash;    /* 哈希链表 */
struct dentry *d_parent;    /* 父目录项 */
struct qstr d_name;            /* 目录名 */
struct inode *d_inode;        /* 对应的索引节点 */
unsigned char d_iname[DNAME_INLINE_LEN];    /* small names */

struct lockref d_lockref;    /* per-dentry lock and refcount */
const struct dentry_operations *d_op;    /* dentry操作 */
struct super_block *d_sb;    /* 文件的超级块对象 */
unsigned long d_time;        
void *d_fsdata;            

struct list_head d_lru;        /* LRU list */
struct list_head d_child;    /* child of parent list */
struct list_head d_subdirs;    /* our children */

union {
    struct hlist_node d_alias;    /* inode alias list */
     struct rcu_head d_rcu;
} d_u;
};  
</code></pre><p>这里可以看到，除开自身的名称、引用计数等，目录项对象中有这些关键的结构：<code>d_op</code>描述了目录项所对应的操作（通用模型的特点）；<code>d_sb</code>则是    文件的超级块对象，至于<code>d_inode</code>则是这个目录项关联的索引节点（当然它们并不是一一对应的关系）。注意，这里还有个很重要的变量：<code>d_lockref</code>，它其实就是一个计数器，说明了这个目录项对象的引用次数。</p>
<p>目录项对象保存在<strong>dentry cache</strong>中。linux操作系统为了提高目录项对象的处理效率，设计了这个高速缓存。这是因为，从磁盘中读取目录项，并且构造相应的目录项对象是需要花费大量的时间的，因此，在完成对目录项对象的操作之后，在内存中（尽量）保存它们具有很重要的意义。这个dentry cache，其本质是一个哈希链表，它定义在list_bl.h当中（它的hash计算在<code>d_hash</code>中完成）。我注意到，对于每一个dentry，都有一个d_flags，它的可能的值，定义在dcache.h当中。因为dentry cache的大小也是有限的，因此我们也不可能无限制地把dentry保存在cache中。因此linux首先把dentry的状态进行了定义：  </p>
<p>free：该状态目录项对象不包含有效信息，未被VFS使用<br>unused：目前没有被内核使用，d_count的值为0，d_inode仍然指向相关的索引节点<br>in use：正在被使用，d_count的值大于0，d_inode仍然指向相关的索引节点<br>negative：与目录项关联的索引节点不存在，相应的磁盘索引节点已经被删除（d_inode为负数）。 </p>
<p>那么对于unused和negative这一类目录项，linux使用了一个LRU（最近最少使用）的双向链表，一旦dentry cache的大小吃紧，就从这个LRU链表中删除dentry。  </p>
<h4 id="索引节点对象"><a href="#索引节点对象" class="headerlink" title="索引节点对象"></a>索引节点对象</h4><p>索引节点对象，是VFS当中最为重要的一个数据结构。它的作用是<strong>表示文件的相关信息</strong>。这里的相关信息，不包括文件本身的内容，而是诸如文件大小、拥有者、创建时间等信息。在一个文件被首次访问时，内核会在内存中构造它的索引节点对象。我们在操作系统中，可以任意修改一个文件的名字，但是索引节点和文件是一一对应的（由索引节点号标识），只要文件存在它就会存在（注意，超级块对象和索引节点对象在硬盘上都是有对应的实体数据结构的，在使用时利用硬盘上的内容，在内存中构造索引节点对象）。目录项是用来找到一个对应的索引节点实体，而具体与文件关联的工作则是由索引节点完成的。<br>让我们来看看索引节点的数据结构（只取了重要的部分），其定义在fs.h当中：</p>
<pre><code>struct inode {
    struct hlist_node    i_hash;     /* 散列表，用于快速查找inode */
    struct list_head    i_list;        /* 相同状态索引节点链表 */
    struct list_head    i_sb_list;  /* 文件系统中所有节点链表  */
    struct list_head    i_dentry;   /* 目录项链表 */
    unsigned long        i_ino;      /* 节点号 */
    atomic_t        i_count;        /* 引用计数 */
    unsigned int        i_nlink;    /* 硬链接数 */
    uid_t            i_uid;          /* 使用者id */
    gid_t            i_gid;          /* 使用组id */
    struct timespec        i_atime;    /* 最后访问时间 */
    struct timespec        i_mtime;    /* 最后修改时间 */
    struct timespec        i_ctime;    /* 最后改变时间 */
    const struct inode_operations    *i_op;  /* 索引节点操作函数 */
    const struct file_operations    *i_fop;    /* 缺省的索引节点操作 */
    struct super_block    *i_sb;              /* 相关的超级块 */
    struct address_space    *i_mapping;     /* 相关的地址映射 */
    struct address_space    i_data;         /* 设备地址映射 */
    unsigned int        i_flags;            /* 文件系统标志 */
    void            *i_private;             /* fs 私有指针 */
    unsigned long i_state;
};
</code></pre><p>可以看到，inode同样采用了多个链表来保存。<code>i_hash</code>用来快速查找inode，<code>i_list</code>则是相同状态索引结点形成的双链表，这包含有未用索引节点链表，正在使用索引节点链表和脏索引节点链表等。<code>i_dentry</code>是所有使用该节点的dentry链表。值得注意的是，inode不仅仅包含了自身索引节点的操作函数<code>i_op</code>，还有指向（缺省）文件操作的指针<code>i_fop</code>。当然，inode还会和super_block有联系。<code>i_sb</code>是索引节点所在的超级块，而i_sb_list则是超级块中的所有节点的链表。<br>当在某个目录下创建、打开一个文件时，内核就会调用<code>create()</code>为这个文件创建一个inode。VFS通过inode的i_op-&gt;create()函数来完成这个工作；它将目录的inode、新打开文件的dentry、访问权限作为参数；<code>lookup()</code>函数用来查找指定文件的dentry，<code>link()</code>和<code>symlink()</code>分别用来创建硬链接和软链接。</p>
<h4 id="超级块对象"><a href="#超级块对象" class="headerlink" title="超级块对象"></a>超级块对象</h4><p>与前面几类对象不同的是，超级块对象表述的内容更加庞大一些：它表示的是一个“已安装的文件系统”。它在文件系统安装时建立，在文件系统卸载时删除。其定义在fs.h当中，这里我只列举出了较为关键的域。</p>
<pre><code>struct super_block {
        struct list_head        s_list;         //超级块链表的指针
        dev_t                   s_dev;          //设备标识符
        unsigned char           s_blocksize_bits;
        unsigned long           s_blocksize;
        loff_t                  s_maxbytes;     //文件的最长长度
        struct file_system_type *s_type;
        const struct super_operations   *s_op;  //超级块的操作
        const struct dquot_operations   *dq_op; 
        const struct quotactl_ops       *s_qcop;
        const struct export_operations *s_export_op;
        unsigned long           s_flags;    //安装标识
        struct dentry           *s_root;    //根目录的目录项
        int                     s_count;
        const struct xattr_handler **s_xattr;
        struct list_head        s_inodes;       //所有的inodes链（打开文件的inodes链）

        struct block_device     *s_bdev;    //块设备
          char s_id[32];                          //块设备名称
        u8 s_uuid[16];                          //UUID            fmode_t                 s_mode;

        char *s_subtype;
        const struct dentry_operations *s_d_op; //default d_op for dentries
        void *s_fs_indo;     //文件系统的信息指针
        };
</code></pre><p>在linux中，每个超级块代表一个已安装的文件系统。所有的超级块链表，是以一种双向环形链表的形式链接在一起的。其<code>prev</code>、<code>next</code>保存在<code>list_head</code>域中。超级块对象中，保存有其根目录的<code>dentry</code>，以及其所有的<code>inode</code>。<code>s_fs_info</code>则指向了文件系统的超级块信息。而对于超级块来说，同样定义有<code>s_op</code>，也即超级块的操作表。<br>超级块一般是储存在磁盘的特定扇区当中，但如果是基于内存对文件系统，比如proc、sysfs，则是保存在内存当中，而超级块对象，则是在使用时创建的，它保存在内存中。  </p>
<h4 id="硬链接和软链接与复制"><a href="#硬链接和软链接与复制" class="headerlink" title="硬链接和软链接与复制"></a>硬链接和软链接与复制</h4><p>linux里面，可以把文件分成三个部分：文件名（dentry），inode，数据。<br>复制的定义很明确，就是为这三个部分，都创建一个新的副本。<br>硬链接的本质是一个“文件名”，一个文件可能有多个“文件名”，inode并不包含文件名，而只是有一个索引节点号。硬链接实际上就是为链接文件创建一个新的dentry，并将dentry写入父目录的数据中，而硬链接所对应的inode依然没有变。所以删除硬链接只是删除了dentry，而inode结点数减少1而已。<br>软链接就是一个普通的文件，只不过它的数据保存的是另一个文件的路径。软链接的创建，调用了<code>__ext4_new_inode()</code>来创建一个新的inode，并把<code>dentry-&gt;name</code>作为了它的内容。也就是说，软链接也同时创建了这三个部分。<br>二者的区别在哪里呢？首先，硬链接共享了inode，因此它不能跨文件系统；但是软链接不受这个限制。由于相同的原因，硬链接只能对存在的文件进行创建，而软链接不是。而且硬链接有可能会在目录中引入循环，所以不能指向目录；但软链接不会，因为它有一个inode实体可以跟踪。不过不论删除软链接还是硬链接，都不会对原文件、具有相同inode号的文件造成影响。但如果原文件被删除，软链接会变成死链接，硬链接不会，因为inode的计数并没有变成0。<br><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E9%93%BE%E6%8E%A5.png?raw=true" alt="">    </p>
<h4 id="路径名查找"><a href="#路径名查找" class="headerlink" title="路径名查找"></a>路径名查找</h4><p>每当进程需要识别一个文件时，就把它的文件路径名，传递给某个VFS系统调用，比如<code>open()</code>。在路径查找中，有个辅助的数据结构：<code>nameidata</code>，它用来向函数传递参数，并且保存查找的结果：  </p>
<pre><code>struct nameidata {
    struct path    path;
    struct qstr    last;
    struct path    root;
    struct inode    *inode; /* path.dentry.d_inode */
    unsigned int    flags;
    unsigned    seq, m_seq;
    int        last_type;
    unsigned    depth;
    struct file    *base;
    char *saved_names[MAX_NESTED_LINKS + 1];
};
</code></pre><p>在查找完成后，<code>path</code>中保存了目录项，<code>depth</code>表示了当前路径的深度，<code>saved_names</code>保存了符号链接处理中的路径名。<br>路径查找的复杂性，主要体现在VFS系统的一些特点上：（1）必须对目录的访问权限进行检查；（2）文件名可能是符号链接；（3）要考虑符号链接可能带来的循环引用；（4）文件名可能是文件系统的安装点（5）路径名和进程的命名空间有关等。<br>路径名查找的入口是<code>path_lookup()</code>，它调用了<code>filename_lookup()</code>。这个函数对nameidata进行了简单的填充，随后调用<code>lookupat()</code>。<br><code>lookupat()</code>函数中通过一个循环，和<code>path_init()</code>函数，逐级向下进行查找，检查目录的访问权限，并且考虑符号链接等情况。  </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/03/30/深入理解文件系统/" data-id="cj5nn6mm6003qo43f4licmouc" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/linux/">linux</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/操作系统/">操作系统</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-ocaml-3" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/03/27/ocaml-3/" class="article-date">
  <time datetime="2017-03-27T14:40:00.000Z" itemprop="datePublished">2017-03-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/03/27/ocaml-3/">Ocaml笔记(二)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h4 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h4><p>OCaml把每一段代码，都包装成一个模块。例如两个文件<code>amodule.ml</code>和<code>bmodule.ml</code>都会定义一个模块，分别为Amodule和Bmodule。<br>通常模块是一个个编译的，比如</p>
<pre><code>ocamlopt -c amodule.ml
ocamlopt -c bmodule.ml
ocamlopt -o hello amodule.cmx bmodule.cmx
</code></pre><p>那么访问模块中的内容可以使用<code>open</code>，也可以使用<code>module.func</code>这样的方式。<br>通常模块会定义为<code>struct...end</code>的形式，这样能够形成一个有效的闭包，防止命名的重复等，它需要和一个<code>module</code>关键字绑定。比如：</p>
<pre><code>module PrioQueue = 
    struct
    ...
    end;;
</code></pre><h4 id="接口、签名"><a href="#接口、签名" class="headerlink" title="接口、签名"></a>接口、签名</h4><p>通常模块中的所有定义，都可以从外部进行访问。但实际中，模块只应该提供一系列接口，隐藏一些内容，这也是面向对象语言中所提倡的。模块是定义在<code>.ml</code>文件中的，而相应的接口，则是从<code>.mli</code>文件中得到的。它包含了一个带有类型的值的表。例如，对于一个模块来说，它的接口可以这样定义：</p>
<pre><code>(*模块定义*)
let message = &quot;Hello&quot;
let hello() = print_endline message

(*接口定义*)
val hello : uint -&gt; unit
</code></pre><p>这样，接口的定义就隐藏了<code>message</code>。这里，<code>.mli</code>文件是在<code>.ml</code>文件之前编译的。<code>.mli</code>用<code>ocamlc</code>来编译，而<code>.ml</code>则是用<code>ocamlopt</code>来编译的。<code>.mli</code>文件就是所说的“签名”。</p>
<pre><code>ocamlc -c amodule.mli
ocamlopt -c amodule.ml
</code></pre><h4 id="类型"><a href="#类型" class="headerlink" title="类型"></a>类型</h4><p>值可以通过把它们的名字和类型，放到.mli文件的方式来导出。</p>
<pre><code>val hello : unit -&gt; unit
</code></pre><p>但模块经常定义新的类型。例如，</p>
<pre><code>type date = { day : int; month : int; year : int }
</code></pre><p>这里其实有几种.mli文件的写法，例如，包括：</p>
<ul>
<li>完全忽略类型</li>
<li>把类型定义拷贝到签名</li>
<li>把类型抽象，只给出名字<code>type date</code></li>
<li>把域做成只读的:<code>type date = private{...}</code></li>
</ul>
<p>如果采用第三种方式，那么模块的用户就只能操作date对象，使用模块提供的函数去间接进行访问。    </p>
<h4 id="子模块"><a href="#子模块" class="headerlink" title="子模块"></a>子模块</h4><p>一个给定的模块，可以在文件中显示的定义，成为当前模块的字模块。通过约束一个给定自模块的接口，是能够达到和写一对<code>.mli/.ml</code>文件一样的效果的。例如：</p>
<pre><code>module type Hello_type = sig
 val hello : unit -&gt; unit
end

module Hello : Hello_type = struct
  ...
end
</code></pre><h4 id="仿函数（函子）"><a href="#仿函数（函子）" class="headerlink" title="仿函数（函子）"></a>仿函数（函子）</h4><p>OCaml中的仿函数，定义与其他语言不太一样，它是用另一个模块，来参数化的模块。它允许传入一个类型作为参数，但这在OCaml中直接做是不可能的。个人理解，这里的函子和C++中的STL比较类似，它接受不同类型的输入作为初始化。事实上在OCaml中，map和set模块都是要通过函子来使用的。<br>例如，标准库定义的<code>Set</code>模块，就提供了一个<code>Make</code>函子。假如要使用不同类型的集合，可以这样这样利用函子：</p>
<pre><code># module Int_set = Set.Make (struct type t = int let compare = compare end)
# module String_set = Set.Make (String);;
</code></pre><p>至于函子的定义，则是这样：</p>
<pre><code>module F(X : X_type) = struct
    ...
end
</code></pre><p><code>X</code>是作为参数被传递的模块，而<code>X_type</code>是它的签名，这种写法是强制。  </p>
<pre><code>module F(X:X_type) : Y_type = 
struct
    ...
end
</code></pre><p>这种写法对于返回模块的签名，也能够进行约束。函子的操作也是比较难理解的，多使用set/map，并且阅读这两个库中的源码，是能够帮助理解和记忆的。  </p>
<h4 id="模式匹配"><a href="#模式匹配" class="headerlink" title="模式匹配"></a>模式匹配</h4><p>OCaml能够把数据结构分开，并对其做模式匹配。这里举一个例子，表示一个数学表达式<code>n * (x + y)</code>，并且分解公因式为<code>n * x + n * y</code><br>首先定义一个表达式类型：</p>
<pre><code># type expr =
| Plus of expr * expr        (* means a + b *)
| Minus of expr * expr       (* means a - b *)
| Times of expr * expr       (* means a * b *)
| Divide of expr * expr      (* means a / b *)
| Value of string            (* &quot;x&quot;, &quot;y&quot;, &quot;n&quot;, etc. *);;
</code></pre><p>那么，对于一个表达式，用模式匹配的方式，可以将其打印成对应的数学表达式：  </p>
<pre><code># let rec to_string e =
match e with
| Plus (left, right) -&gt;
   &quot;(&quot; ^ to_string left ^ &quot; + &quot; ^ to_string right ^ &quot;)&quot;
| Minus (left, right) -&gt;
   &quot;(&quot; ^ to_string left ^ &quot; - &quot; ^ to_string right ^ &quot;)&quot;
| Times (left, right) -&gt;
   &quot;(&quot; ^ to_string left ^ &quot; * &quot; ^ to_string right ^ &quot;)&quot;
| Divide (left, right) -&gt;
   &quot;(&quot; ^ to_string left ^ &quot; / &quot; ^ to_string right ^ &quot;)&quot;
| Value v -&gt; v;;

val to_string : expr -&gt; string = &lt;fun&gt;
# let print_expr e =
    print_endline (to_string e);;
val print_expr : expr -&gt; unit = &lt;fun&gt;
</code></pre><p>这样，使用print_expr，就能够把一个表达式打印成一个数学表达式。那么，模式匹配的通用形式是：</p>
<pre><code>match value with
| pattern    -&gt;  result
| pattern    -&gt;  result
  ...
</code></pre><p>或者对条件进行进一步的约束</p>
<pre><code>match value with
| pattern  [ when condition ] -&gt;  result
| pattern  [ when condition ] -&gt;  result
  ...
</code></pre><p>注意，这里还有一种特殊的模式匹配，<code>| _</code>，它用来匹配剩下的任意情况。</p>
<h4 id="奇奇怪怪的操作符"><a href="#奇奇怪怪的操作符" class="headerlink" title="奇奇怪怪的操作符"></a>奇奇怪怪的操作符</h4><p>OCaml中，还有许多有趣的操作符和表达式。在SO上，我也看到了类似的提问： </p>
<pre><code>let m = PairsMap.(empty |&gt; add (0,1) &quot;hello&quot; |&gt; add (1,0) &quot;world&quot;) 
</code></pre><p>这里有两个问题。第一个，<code>module.(e)</code>是啥意思？它其实等价于<code>let open Module in e</code>，它相当于一种简写的形式，同样是把module引入当前模块的方式。<br>第二个<code>|&gt;</code>表达式是什么意思？其实它是<code>Pervasives</code>中定义的一个操作符，其定义为<code>let (|&gt;) x f = f x</code>。它被称为”reverse application function”（我不知道应该如何翻译），但它的作用，是把连续的调用去有效的串联起来（可以把函数放在参数之后，从而保证一个调用顺序，有一点类似管道的意思）。如果不使用<code>|&gt;</code>符号，那么就必须写成：</p>
<pre><code>let m = PairsMap.(add(1,0) &quot;world&quot; (add(0,1) &quot;hello&quot; empty))
</code></pre><p>在Uroboros当中，还看到有一个奇怪的操作符，那便是<code>@</code>，从manual上来看，这个操作符的意思是“串联List”。有这样的例子：</p>
<pre><code># List.append [1;2;3] [4;5;6];;
- : int list = [1; 2; 3; 4; 5; 6]
# [1;2;3] @ [4;5;6];;
- : int list = [1; 2; 3; 4; 5; 6]
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/03/27/ocaml-3/" data-id="cj5nn6mlh002oo43fsc4a3lbp" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Ocaml/">Ocaml</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/静态分析/">静态分析</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-ocaml" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/03/27/ocaml/" class="article-date">
  <time datetime="2017-03-27T10:40:00.000Z" itemprop="datePublished">2017-03-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/03/27/ocaml/">Ocaml笔记(一)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="Ocaml"><a href="#Ocaml" class="headerlink" title="Ocaml"></a>Ocaml</h3><p>网上关于Ocaml的资料比较少，可见它是一门偏小众的语言。不过在DSL和程序分析方面，Ocaml是十分强大的。由于目前研究需要使用的Uroboros(<a href="https://github.com/s3team/uroboros" target="_blank" rel="external">https://github.com/s3team/uroboros</a>)是由Ocaml来编写的，因此我也打算一探究竟，学一学这门语言。</p>
<h4 id="函数的定义和调用"><a href="#函数的定义和调用" class="headerlink" title="函数的定义和调用"></a>函数的定义和调用</h4><p>Ocaml中，定义函数的语法很简单。这个函数是输入两个浮点数后计算它们的平均值。</p>
<pre><code>let average a b =
    (a +. b) /. 2.0;;
</code></pre><p>在C当中，如果要定义一个相同的函数，其定义是这样的：</p>
<pre><code>double average(double a, double b){
return (a + b) / 2;
}
</code></pre><p>可以看到，OCaml没有定义a和b的类型，而且也没有所谓的<code>return</code>，而且写的是<code>2.0</code>，没有用隐式转换。这其实是由Ocaml语言的特性决定的：</p>
<ul>
<li>Ocaml是强静态类型的语言  </li>
<li>OCaml使用类型推倒，不需要注明类型</li>
<li>OCaml不做任何隐式转换(所以要写浮点数就必须是2.0)</li>
<li>OCaml不允许重载，<code>+.</code>表示两个浮点数相加，也就是说操作符是和类型相关的</li>
<li>OCaml的返回值是最后的表达式，不需要<code>return</code></li>
</ul>
<p>和大多数基于C的语言不同，OCaml的函数调用，是没有括号的。例如定义了一个函数<code>repeated</code>，它的参数是一个字符串<code>s</code>和一个数<code>n</code>，那么它的调用形式会是：</p>
<pre><code>repeated &quot;hello&quot; 3    (*this is Ocaml code*)
</code></pre><p>可以看到既没有括号，也没有都好。不过<code>reoeated (&quot;hello&quot;, 3)</code>也是合法的，只不过它的参数是一个含两个元素的对(pair)。</p>
<h4 id="基本类型、转换与推倒"><a href="#基本类型、转换与推倒" class="headerlink" title="基本类型、转换与推倒"></a>基本类型、转换与推倒</h4><table>
<thead>
<tr>
<th>类型</th>
<th>范围</th>
</tr>
</thead>
<tbody>
<tr>
<td>int</td>
<td>32bit:31位;64bit:63位</td>
</tr>
<tr>
<td>float</td>
<td>双精度，类似于C中的double</td>
</tr>
<tr>
<td>bool</td>
<td>true/flase</td>
</tr>
<tr>
<td>char</td>
<td>8bit字符</td>
</tr>
<tr>
<td>string</td>
<td>字符串</td>
</tr>
<tr>
<td>unit</td>
<td>写作()，类似void</td>
</tr>
</tbody>
</table>
<p>这里，Ocaml内部使用了int中的一位来自动管理内存(垃圾收集)，因此会少一位。<br>前面也提到，OCaml是没有隐式类型转换的。因此</p>
<pre><code>1 + 2.5;;
1 +. 2.5;;
</code></pre><p>在OCaml中是会报错的。但是如果一定要让一个整数和浮点数相加，就必须显示的进行转换，比如：</p>
<pre><code>float_of_int i +. f;;
float i +. f;;
</code></pre><p>许多情况下，不需要声明函数的变量和类型，因为Ocaml自己会知道，它会一直检查所有的类型匹配。比如前面的average函数，就能够自给判断出这个函数需要两个浮点数参数和返回一个浮点数。  </p>
<h4 id="函数的递归和类型"><a href="#函数的递归和类型" class="headerlink" title="函数的递归和类型"></a>函数的递归和类型</h4><p>和基于C的语言不同之处在于，OCaml中，函数一般不是递归的，除非用let rec代替let定义递归函数。这是一个递归函数的例子：</p>
<pre><code>let rec range a b =
    if a &gt; b then []
    else a :: range (a+1) b
</code></pre><p>let和let rec的唯一区别，就是函数的定义域。举个例子，如果用<code>let</code>定义<code>range</code>，那么<code>range</code>会去找一个已经定义好的函数，而不是它自身。不过在性能上，<code>let</code>和<code>let rec</code>并没有太大的差异。所以即使全部用<code>let rec</code>来定义也可以。<br>而OCaml的类型推倒，也使得几乎不用显式的写出函数的类型。不过Ocaml经常以这样的实行显示参数和返回值的类型：</p>
<pre><code>f:arg1 -&gt; arg2 -&gt; ... -&gt; argn -&gt; rettype
f: &apos;a-&gt;int    (*单引号表示人意类型*)
</code></pre><h4 id="表达式"><a href="#表达式" class="headerlink" title="表达式"></a>表达式</h4><p>在Ocaml当中，局部变量/全局变量其实都是一个表达式。例如，局部表达式有：</p>
<pre><code>let average a b =
    let sum = a +. b in
    sum /. 2.0;;
</code></pre><p>标准短语<code>let name = expression in</code>是用来定义一个命名的局部表达式的。<code>name</code>在这个函数当中，就可以代替<code>expression</code>，直到一个<code>;;</code>结束这个代码块。这里把<code>let ... in</code>视为一个整体。和C中不一样，OCaml中<code>name</code>只是<code>expression</code>的一个别名，我们是不能给<code>name</code>赋值或者改值的。<br>而全局表达式，也可以像定义局部变量一样定义全局名，但这些也不是真正的变量，而只是缩略名。  </p>
<pre><code>let html =
  let content = read_whole_file file in
  GHtml.html_from_string content
  ;;

let menu_bold () =
  match bold_button#active with
  | true -&gt; html#set_font_style ~enable:[`BOLD] ()
  | false -&gt; html#set_font_style ~disable:[`BOLD] ()
  ;;

let main () =
  (* code omitted *)
  factory#add_item &quot;Cut&quot; ~key:_X ~callback: html#cut
  ;;
</code></pre><p>这里，<code>html</code>实际上是一个“小部件”，没有指针去保存它的地址，也不能赋值，而是在之后的两个函数中被引用。  </p>
<h4 id="Let-绑定"><a href="#Let-绑定" class="headerlink" title="Let-绑定"></a>Let-绑定</h4><p>绑定，<code>let ...</code>，能够在OCaml中，实现真正的变量。在OCaml中，引用使用关键字<code>ref</code>来进行定义。例如，  </p>
<pre><code>let my_ref = ref 0;;(*引用保存着一个整数0*)
myref := 100(*引用被赋值为100*)
</code></pre><p><code>:=</code>用来给引用赋值，而<code>！</code>用来取出引用的值。以下是一个C和OCaml的比较   </p>
<pre><code>OCaml                   C/C++

let my_ref = ref 0;;    int a = 0; int *my_ptr = &amp;a;
my_ref := 100;;         *my_ptr = 100;
!my_ref                 *my_ptr
</code></pre><h4 id="嵌套函数"><a href="#嵌套函数" class="headerlink" title="嵌套函数"></a>嵌套函数</h4><p>与C语言不同的是，OCaml是可以使用嵌套函数的。  </p>
<pre><code>let read_whole_channel chan =
let buf = Buffer.create 4096 in
let rec loop () =
  let newline = input_line chan in
  Buffer.add_string buf newline;
  Buffer.add_char buf &apos;\n&apos;;
  loop ()
in
try
  loop ()
with
  End_of_file -&gt; Buffer.contents buf;;
</code></pre><p>这里，<code>loop</code>是只有一个嵌套函数，在<code>read_whole_channel</code>中，是可以调用<code>loop()</code>的，但它在<code>read_whole_channel</code>当中并没有定义，嵌套函数可以使用主函数当中的变量，它的格式和局部命名表达式是一致的。</p>
<h4 id="模块和OPEN"><a href="#模块和OPEN" class="headerlink" title="模块和OPEN"></a>模块和OPEN</h4><p>OCaml也提供了很多模块，包括画图、数据结构、处理大数等等。这些库位于<code>usr/lib/ocaml/VERSION</code>。例如一个简单的模块<code>Graphics</code>，如果想使用其中的函数，有两种方法。第一种是在开头声明<code>open Graphics</code>，第二种是在函数调用之前加上前缀，例如<code>Graphics.open_graph</code>。<br>如果想用<code>Graphics</code>当中的符号，也可以通过重命名的方式，简化前缀。  </p>
<pre><code>module Gr = Graphics;;
</code></pre><p>这个技巧在模块嵌套时十分有用。</p>
<h4 id="还是-，或者什么都不用？"><a href="#还是-，或者什么都不用？" class="headerlink" title=";;还是;，或者什么都不用？"></a><code>;;</code>还是<code>;</code>，或者什么都不用？</h4><p>在OCaml中，有时候会使用<code>;;</code>，有时候会使用<code>;</code>，有时候却什么都不用，这就让初学者很容易迷惑。这里，OCaml实际上定义了一系列的规则。  </p>
<p> #1 必须使用<code>;;</code>在代码的最顶端，来分隔不同语句(不同代码段之间的分隔)，并且<strong>不要</strong>在函数定义或其他语句中使用  </p>
<p> #2 可以在某些时候省略掉<code>;;</code>，包括<code>let</code>，<code>open</code>，<code>type</code>之前，文件的最后，以及OCaml能自动判断的地方  </p>
<p> #3 <code>let ... in</code>是一条单独道语句，不能在后面加单独的<code>;</code>  </p>
<p> #4 所有代码块中其他语句后面，跟上一个单独的<code>;</code>，最后一个例外  </p>
<p> 看到这些规则，我依然没有完全理解这三者的用法。我想，只有实际接触过Ocaml代码，才能逐渐体会到其中的精髓吧。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/03/27/ocaml/" data-id="cj5nn6mll002ro43fy3qkgmxo" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Ocaml/">Ocaml</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/静态分析/">静态分析</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-LLVM笔记" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/03/23/LLVM笔记/" class="article-date">
  <time datetime="2017-03-23T07:27:32.000Z" itemprop="datePublished">2017-03-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/03/23/LLVM笔记/">LLVM框架与Pass</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="LLVM简介"><a href="#LLVM简介" class="headerlink" title="LLVM简介"></a>LLVM简介</h3><p>传统的编译器，采用的是针对单语言源代码，生成对应平台机器码的方式，类似于：<br><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/llvm/SimpleCompiler.png?raw=true" alt="Simple"><br>而LLVM则采用了一种多前端，多后端的方式，如下：<br><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/llvm/RetargetableCompiler.png?raw=true" alt="Retargetable"><br>在LLVM当中，LLVM IR是一种low-level的，虚拟指令集。所有的前端语言都能够生成LLVM，从而能够被统一的进行处理。在LLVM当中，还提供了对LLVM IR Optimization进行优化的方式，能够对现有的源码进行搜索，匹配对应的pattern，从而进行指令的替换、修改。<br>LLVM中，每个过程都是从Pass继承来的，LLVM优化器提供了许多passes，每个都写的很简洁，它们被编译成了库文件，并且在编译的时候被调用。这些库提供了分析和变换的能力，并且既能独立运作，又能合作。  </p>
<h3 id="代码生成"><a href="#代码生成" class="headerlink" title="代码生成"></a>代码生成</h3><p>那么LLVM这种“多对多”的编译方式，是如何将LLVM IR转化为机器码的呢？LLVM将代码的生成划分成了多个独立的过程：指令选择、寄存器生成，调度，代码布局优化，生成汇编代码。这样不同的平台，也能够利用自己的优势，对相同的LLVM IR进行优化。<br>LLVM采用了一种“mix and match”的方式，允许target作者，对于架构做出明确的指示，例如对寄存器的使用、限制做出明确的指示。LLVM利用Target-8description文件来指定对应架构的特性、使用的指令、寄存器。<br><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/llvm/X86Target.png?raw=true" alt="X86Target"><br>而LLVM利用<strong>tblgen</strong>工具从这些.md文件当中，能够读取出足够的信息，并且在instruction selection、register allocator等过程中，选择处理的过程。而.cpp文件，则是实现一些特定的过程，例如浮点指针栈。  </p>
<h3 id="LLVM-pass"><a href="#LLVM-pass" class="headerlink" title="LLVM pass"></a>LLVM pass</h3><p>LLVM pass完成编译器的变换、优化工作；它们是Pass的子类，根据不同的需要，可以选择去继承ModulePass，CallGraphSCCPass，FunctionPass，或者LoopPass，RegionPass和BasicBlockPass等。<br>llvm是需要编写、编译、加载和执行的，它相当于一个可以加载的模块。<br>如果想编写一个模块，可以再llvm/lib/Transform当中创建对应的目录，并且在Transform以及目标文件夹下同时修改两个CMakeLists。在编译时，llvm的编译链会自动生成对应的pass。<br>pass是基于中间语言llvm IR来进行的。因此它用来对.bc文件进行优化，例如：</p>
<pre><code>opt -load /lib/LLVMLbpass.so -lbpass &lt;foo.bc&gt; /dev/null
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/03/23/LLVM笔记/" data-id="cj5nn6mkf001so43fim4yv0va" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/llvm/">llvm</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/编译器/">编译器</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/编译安全/">编译安全</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-深入理解内核同步" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/03/15/深入理解内核同步/" class="article-date">
  <time datetime="2017-03-15T13:40:00.000Z" itemprop="datePublished">2017-03-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/03/15/深入理解内核同步/">深入理解内核同步</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h4 id="内核同步"><a href="#内核同步" class="headerlink" title="内核同步"></a>内核同步</h4><p>对于内核，其实有一个很形象的理解：我们可以把内核理解成一个服务器，它为自身和用户提供各种服务。因此它必须要保证每项服务在处理时，不会互相造成影响，也就是解决“并发”的问题。自身的请求，也即中断；客户的请求，也即用户态的系统调用或异常。内核的同步，就是对内核中的任务进行调度，使它们按照正确的方式运行。  </p>
<h4 id="内核抢占"><a href="#内核抢占" class="headerlink" title="内核抢占"></a>内核抢占</h4><p>这里，“内核抢占”指的是进程A在内核态运行时，被具有更高优先级的进程B取代，也就是发生了<strong>进程上下文的切换</strong>。而我们知道，中断上下文是不包括进程信息的，不能被调度。所以只要在中断上下文中，就不能进行“进程切换”。因此硬中断和软中断在执行时都不允许内核抢占；只有在内核执行异常处理程序（尤其是系统调用），并且内核抢占没有被显示禁用时，才能进行内核抢占。CPU必须打开本地中断，才能完成内核抢占。<br>从另一个角度来说，CPU在任何情况下，都处于三种上下文情况之一：<br>（1）运行在用户空间，执行用户进程；<br>（2）运行在内核空间，处于进程上下文；<br>（3）运行在内核空间，处于中断上下文。  </p>
<p>在关于中断的博文里，我已经写过，中断上下文是不属于任何进程的，它和<code>current</code>没有任何关系。由于没有任何进程背景，在中断上下文中也不能发生睡眠，否则是不能对它进行调度。<strong>因此中断上下文中只能用锁进行同步，中断上下文也叫做原子上下文</strong>。而异常和系统调用陷入内核时，是出于进程上下文的，因此可以通过<code>current</code>关联相应的任务。所以在进程上下文中，可以发生睡眠，也可以使用信号量；当然也可以使用锁。<br>ps：以上说的是内核抢占的情况；用户抢占指的是另一个概念，指的是内核即将返回用户空间的时候，如果<code>need_resched</code>标志被设置，就会调用<code>schedule()</code>，选择一个更为合适的进程运行。  </p>
<p>内核不能被抢占的情况有这些：<br>（1）内核正在进行中断处理。在linux下，进程不能抢占中断（注意，中断是可以抢占、中止其他中断的），中断历程中不允许进行进程调度（<code>schedule()会进行判断，如果在中断中会报错</code>）。这也包括软中断的Bottom half部分。<br>（2）当前的代码段持有自旋锁、读写锁，这些锁<strong>保证SMP系统CPU并发的正确性</strong>，此时不能进行抢占。<br>（3）内核正在执行调度程序时，不应该进行抢占。<br>（4）内核正在对每CPU数据进行操作。  </p>
<p>除此之外的情况，都可以发生内核抢占。  </p>
<h4 id="每CPU变量"><a href="#每CPU变量" class="headerlink" title="每CPU变量"></a>每CPU变量</h4><p>把内核变量，声明为每个CPU所独有的，它是数组结构的数组，每个CPU对应数组的一个元素，CPU直接不能访问其他CPU对应的数组元素，只能读写自身的元素，因此也不会出现竞争条件。但这同样存在着限制：必须确定CPU上的数据是各自独立的。<br>但是每CPU变量不能解决内核抢占的问题，他只能解决多CPU的问题，因此在访问时应当禁用抢占。</p>
<h4 id="原子操作"><a href="#原子操作" class="headerlink" title="原子操作"></a>原子操作</h4><p>通过保证操作在芯片上是原子级的，保证“读－修改－写”指令不会引发竞争。任何一个这样的操作，都必须以单个指令执行，并且不能中断，避免其他CPU访问这个单元。除了常见的0或1次对齐内存访问的汇编指令、单处理器下的“读－修改－写”指令、前缀为lock的指令也是原子操作指令。</p>
<h4 id="优化和内存屏障"><a href="#优化和内存屏障" class="headerlink" title="优化和内存屏障"></a>优化和内存屏障</h4><p>优化屏障主要是用来保证编译时，汇编语言指令按照原顺序来执行，而不进行重排。例如在linux中，<code>barrier()</code>的本质就是<code>asm volatile(&quot;&quot;:::&quot;memory&quot;)</code>。而内存屏障则是保证原语前后的指令执行顺序，也即在执行原语后的指令时，原语前的指令必须已经执行完了。  </p>
<h4 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h4><p>自旋锁是一类特别广泛使用的同步技术，如果内核控制路径必须访问共享数据结构，或者访问临界区，那么就需要为自己获取一个自旋锁；只有资源是空闲时，获取才能成功；当它释放了锁之后，其他内核控制路径就可以进入房间了。那么自旋锁的意义是什么？它是多处理器环境下一种特殊的锁；如果执行路径发现自旋锁是锁着的，或反复在周围进行“旋转”，反复执行循环，直到锁被释放（忙等）。<br>自旋锁保护的临界区通常是禁止内核抢占的，如果在单CPU环境下，自旋锁仅仅能够禁止或启用内核抢占，并不能起到锁的作用。当然，忙等时还是可以被抢占的，只有上锁后才会禁止抢占。<br>ps：阿里巴巴的面试官问过我一个问题，<strong>自旋锁的本质是什么？</strong>我当时猜测了一下，回答了原子操作，但没有能够进一步地进行解释。这里应该结合源码进行说明。可以看到对<code>xadd</code>就是一个标准的源子加操作。linux内核使用了两种实现。其一是“标签自旋锁”，<code>raw_spin_lock</code>最后会调用：</p>
<pre><code>static inline void __raw_spin_lock(raw_spinlock_t *lock)
{
   preempt_disable();        //禁止了抢占
   spin_acquire(&amp;lock-&gt;dep_map, 0, 0, _RET_IP_);
   LOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);
}


arch_spin_lock(arch_spinlock_t *lock)
{
    register struct __raw_tickets inc = {.tail = TICKET_LOCK_INC};//这个值是0
    inc = xadd(&amp;lock-&gt;tickets, inc);    //xadd是原子加，在多CPU时会上锁
                                        //获取标签，同时把序号＋1  
    if(likely(inc.head == inc.tail))    //标签到自己了，取锁成功了
        goto out;
    for(;;){                            //否则就不断循环，直到轮到自己
        unsigned count = SPIN_THRESHOLD;

        do{
            inc.head = READ_ONCE(lock-&gt;tickets.head);
            if(__tickets_equal(inc.head, inc.tail))//判断是否到自己的标签了
            goto clear_slowpath;
            cpu_relax();
        }while(--count);
        __ticket_lock_spinning(lock, inc.tail);
    }
    clear_slowpath:
        __ticket_check_and_clear_slowpath(lock, inc.head);
    cout:
        barrier();
}

arch_spinlock_t的结构如下，实际上就是一个u16数
typedef struct arch_spinlock {
         union {
                 __ticketpair_t head_tail;
                 struct __raw_tickets {
                         __ticket_t head, tail;
                 } tickets;
         };
 } arch_spinlock_t; 
</code></pre><p>另一种是一种更加复杂的实现，被称为“排队自旋锁”。排队自旋锁基于每CPU变量实现，其实现比基于标签对实现更公平。  </p>
<h4 id="读－拷贝－更新"><a href="#读－拷贝－更新" class="headerlink" title="读－拷贝－更新"></a>读－拷贝－更新</h4><p>用来保护在多数情况下，被多个CPU读的数据结构，而设计的另一种同步技术，其特点是允许多个读和写并发执行，并且不使用锁。那么它如何在共享数据读前提下，实现同步呢？RCU只保护被动态分配，并且通过指针引用的数据结构，并且在RCU临界区内，禁止睡眠。RCU的做法是，在写操作时，拷贝一份原来的副本，在副本上进行修改，并且在修改完成后进行更新，将旧的指针更新为新的指针。  </p>
<h4 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h4><p>在linux中，有两种信号量，一种是给内核使用的内核信号量，另一种是给用户态进程使用的IPC信号量。这里我们只讨论内核信号量。其实信号量和自旋锁在“上锁”这一点上是类似的，如果锁关闭了，那么就不允许内核控制路径继续执行；只不过它不会像自旋锁一样，在原地“忙等”，而是将相应的进程挂起；只有资源可用了，进程才能继续运行。也正因为“睡眠”的特性，信号量<strong>不能用在中断处理程序和延迟处理函数</strong>上，只有允许睡眠的情况下，才能够使用信号量。<br><strong>内核</strong>信号量的定义在semaphore.h当中：</p>
<pre><code>struct semaphore {
      raw_spinlock_t          lock;        //保护信号量的自旋锁
      unsigned int            count;
      struct list_head        wait_list;
 };
</code></pre><p>很神奇的，这里看到了<code>raw_spinlock_t</code>的影子。这其实是一个由Real-time linux引入的命名问题；这里我们只需要明白：尽可能使用spin_lock；绝对不允许被抢占和休眠的地方，使用raw_spin_lock，否则使用spin_lock，信号量的底层，使用了自旋锁来实现。  </p>
<p>信号量的后两个域，<code>count</code>和<code>wait_list</code>分别是现有资源数和等待获取资源的进程序列。对于信号量，内核定义了这些API：</p>
<pre><code>void down(struct semaphore *sem);
void up(struct semaphore *sem);
int  down_interruptible(struct semaphore *sem);
int  down_killable(struct semaphore *sem);
int  down_trylock(struct semaphore *sem);
int  down_timeout(struct semaphore *sem, long jiffies);
</code></pre><p>这里看看<code>down</code>函数：</p>
<pre><code>void down(struct semaphore *sem)
{
    unsigned long flags;

    raw_spin_lock_irqsave(&amp;sem-&gt;lock, flags);
    if (likely(sem-&gt;count &gt; 0))
            sem-&gt;count--;
    else
            __down(sem);
    raw_spin_unlock_irqrestore(&amp;sem-&gt;lock, flags);
}
</code></pre><p>可以看到，这里自旋锁的作用实际上是保证count不被同时操作；而如果count大于0，则可以减少它的值，表示获取了这个锁，否则会<code>__down_common</code>，这个函数在不发生错误大情况下，会调用这样一段函数：</p>
<pre><code>raw_spin_unlock_irq(&amp;sem-&gt;lock);
timeout = schedule_timeout(timeout);
raw_spin_lock_irq(&amp;sem-&gt;lock);
</code></pre><p>这个函数是在timer.c代码中定义的。<code>schedule_timeout</code>函数将当前的任务置为休眠到设置的超时为止，这也就是信号量和自旋锁不同之处了，它允许进程的休眠。</p>
<p>而对于<code>up</code>函数来说，释放锁，增加count之后，会马上会检查是否有进程在等待资源：</p>
<pre><code>static noinline void __sched __up(struct semaphore *sem)
{
    struct semaphore_waiter *waiter = list_first_entry(&amp;sem-&gt;wait_list,
                                            struct semaphore_waiter, list);
    list_del(&amp;waiter-&gt;list);
    waiter-&gt;up = true;
    wake_up_process(waiter-&gt;task);
}
</code></pre><p>这样看来，其实信号量和自旋锁最大的不同就只有两个：自旋锁的忙等与信号量的休眠，资源的数量。  </p>
<h4 id="互斥量"><a href="#互斥量" class="headerlink" title="互斥量"></a>互斥量</h4><p>虽然《深入理解linux内核》这本书中没有写，但是内核中也是有互斥量的；实际上它相当于count ＝ 1的信号量。互斥量的定义为：  </p>
<pre><code>struct mutex {
    atomic_t                count;
    spinlock_t              wait_lock;
    struct list_head        wait_list;
#if defined(CONFIG_DEBUG_MUTEXES) || defined(CONFIG_MUTEX_SPIN_ON_OWNER)
    struct task_struct      *owner;
#endif
#ifdef CONFIG_MUTEX_SPIN_ON_OWNER
    struct optimistic_spin_queue osq;
#endif
#ifdef CONFIG_DEBUG_MUTEXES
    void                    *magic;
#endif
#ifdef CONFIG_DEBUG_LOCK_ALLOC
    struct lockdep_map      dep_map;
#endif
};
</code></pre><p>可以看到它同样依赖于自旋锁实现，也包含一个进程的等待队列。我们来看看互斥量的上锁操作：  </p>
<pre><code>void __sched mutex_lock(struct mutex *lock)
{
    might_sleep();
    __mutex_fastpath_lock(&amp;lock-&gt;count, __mutex_lock_slowpath);
    mutex_set_owner(lock);
}

这里__mutex_fastpath_lock最终会调用一段汇编代码：
asm_volatile_goto(LOCK_PREFIX &quot;   decl %0\n&quot;
                          &quot;   jns %l[exit]\n&quot;
                          : : &quot;m&quot; (v-&gt;counter)
                          : &quot;memory&quot;, &quot;cc&quot;
                          : exit);
</code></pre><p>也就是原子操作，修改mutex的counter，而mutex中的自旋锁，是为了保护<code>wait_list</code>而存在的，只是起到一个辅助作用，这点和信号量不太一样。  </p>
<h4 id="读写自旋锁-顺序锁-信号量"><a href="#读写自旋锁-顺序锁-信号量" class="headerlink" title="读写自旋锁/顺序锁/信号量"></a>读写自旋锁/顺序锁/信号量</h4><p>为了增加内核到并发能力，操作系统还设置了读写自旋锁。读写自旋锁允许多个内存控制路径，同时<strong>读</strong>同一个数据结构，但如果相对这个结构进行写操作，那么它必须首先获取读写自旋锁的写锁，写锁能让当前的路径独占访问这个资源。<br>顺序锁则是允许读者在读的同时进行写操作，因此写操作永远不会等待，但这样读操作有时候必须重复读多次，直到读到有效的副本为止。<br>读写信号量则和读写自旋锁类似，只不过它以挂起代替自旋。  </p>
<h4 id="禁止本地中断-可延迟函数"><a href="#禁止本地中断-可延迟函数" class="headerlink" title="禁止本地中断/可延迟函数"></a>禁止本地中断/可延迟函数</h4><p>在前面提到的原语中，很多在实现的时候，都禁止了了本地的中断，这就保证了当前内核控制路径能够继续执行，例如<code>raw_spin_lock_irqsave</code>和<code>raw_spin_lock_irqrestore</code>。不过禁止本地中断不能阻止其他CPU<br>访问共享数据，因此通常和自旋锁结合使用。<br>而可延迟函数同样可以禁止和激活，这是由preempt_count字段中的值决定的。  </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/03/15/深入理解内核同步/" data-id="cj5nn6mm3003no43fnw3gs7zz" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/linux/">linux</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/操作系统/">操作系统</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-中断的发生" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/03/06/中断的发生/" class="article-date">
  <time datetime="2017-03-06T03:40:00.000Z" itemprop="datePublished">2017-03-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/03/06/中断的发生/">深入理解中断（二）</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h4 id="中断的发生"><a href="#中断的发生" class="headerlink" title="中断的发生"></a>中断的发生</h4><p>中断指的是CPU在运行时，系统内发生了需要“急需处理”的事件，于是乎CPU暂停了当前正在执行对程序，转而去执行相应的时间处理程序，在处理完之后返回原来的地方执行。那么这些事件包含：（1）外部中断指的是那些CPU外的周边原件引发的中断，例如I/O中断，I/O设备异常（接下来我们把它称为“中断”）；（2）内部中断指的是在CPU内部执行时，由程序自身、异常、陷阱（例如程序中的断点）产生的中断（包括硬件中断和软件中断，其中软件中断是指一系列的指令）（接下来我们把它称作“异常”）。<br>这两种中断类型不同，产生方式也不一样：<br>（1）中断因为是由外设硬件发出的，所以需要由中断控制器（APIC）参与其中。在中断发出后，首先由APIC来进行处理。这种方式解决两个问题：（a）有大量的外设，而CPU的引脚资源有限，所以不能满足所有的直连需要；（b）如果设备中断和CPU直连，那么在MP系统中，中断负载等需求就无法实现了。<br>可以看到，在x86_64系统下，local APIC通过I/O APIC接受链接，I/O APIC把中断处理成中断消息，并按照规则转发给local APIC。APIC决定了由哪个CPU来处理中断，为某个引脚产生特定的中断向量（中断投递协议），并把中断请求发送给对应的CPU处理。CPU之间的中断通信，也是通过APIC来完成的。<br><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/%E4%B8%AD%E6%96%AD/APIC.png?raw=true" alt=""><br>I/O设备通过IRQ线与APIC相连，APIC将信号转化为对应的向量，并把这个向量放在它的I/O端口上，允许CPU通过数据总线来读这个向量；随后它发送一个信息给CPU的INTR引脚，从而触发中断，当CPU通过把中断信号写进APIC的I/O端口时，把INTR线清除。目前，外部中断的编号是从32开始，这是由于0-31号中断是留给异常和内部中断使用的，INTEL手册上也给出了这样一个表，详细说明了中断号的对应关系（新的CPU确实用的编号也变多了，就比如#VE）：<br><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/%E4%B8%AD%E6%96%AD/table1.png?raw=true" alt=""><br><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/%E4%B8%AD%E6%96%AD/table2.png?raw=true" alt=""><br>（2）异常则是由CPU自身产生的中断。那么这种中断是否需要APIC介入呢？除了I/O APIC的中断信号外，local APIC还会接收其他来源的中断，例如CPU LINT0/LINT1中断（本地连接的I/O），性能计数器中断、APIC内部错误中断等。但这不意味着所有异常都需要中断控制器的参与；软件中断的中断号是可以由指令直接给出的，因此是不需要中断控制器的参与的。  </p>
<h4 id="中断的屏蔽"><a href="#中断的屏蔽" class="headerlink" title="中断的屏蔽"></a>中断的屏蔽</h4><p>注意，这里的中断屏蔽指的是对外部中断的屏蔽（mask）。CPU内部的中断（异常）是不能屏蔽的。在内核同步中，通常采用这种方式来屏蔽外部的中断；并结合自旋锁来保证中断不被打断。<br>IRQ和NMI分别是可屏蔽和不可屏蔽中断（例子：打印机中断和电源掉电）。CPU在处理NMI中断时，不从外部硬件接收中断向量号，其对应中断向量号固定为2。NMI中断通常用于故障处理（协处理器运算出错、存储器校验出错等危急事件）。NMI处理程序通常应以IRET指令来结束。IRQ则是可以屏蔽的一类中断，通过设置CPU中的IF位，可以对IRQ进行屏蔽，这个标志位可以通过软件来设置。例如在处理某个高优先级中断时，CPU收到了低优先级的中断，那么就会对它进行屏蔽。<br>而对于内核的同步，则是由操作系统内部来实现的。可以说，目前我们讨论的只是中断是如何被送到CPU的，而CPU把中断和异常送给操作系统，并操作系统做出反应的过程，则属于另一个范畴了（在另一片博文<a href="http://sec-lbx.tk/2017/02/15/%E4%B8%AD%E6%96%AD%E7%9B%B8%E5%85%B3/" target="_blank" rel="external">http://sec-lbx.tk/2017/02/15/中断相关</a>）。  </p>
<h4 id="异常和中断的处理"><a href="#异常和中断的处理" class="headerlink" title="异常和中断的处理"></a>异常和中断的处理</h4><p>我们可以把内核，理解成一个服务器，它不断处理着用户的各种请求。因此，它需要保证每项服务在处理时，不会互相造成影响；其并发的来源包括内核的抢占和中断处理等。在内核态，中断处理程序也可以嵌套，这种情况下中断处理程序必须永不阻塞，在它运行的期间不能发生进程切换（不过缺页异常是一个例外，它不会引起进一步的异常，所以缺页异常可以切换进程，提高效率）。中断处理程序既可以抢占其他的中断处理程序，也可以抢占异常处理程序。相反的，异常处理程序<strong>从不会</strong>抢占中断处理程序。如果已经在内核态了，就只可能发生缺页异常（当然，也包含有现在的EPT缺页），但它们不会进一步的进行导致缺页的操作。<br>异常处理程序通常包含三个部分：（1）在内核堆栈保存大多数寄存器的内容；（2）用高级的C函数对异常进行处理；（3）通过<code>ret_from_exception()</code>函数，从异常处理程序退出。<br>中断处理程序与异常处理程序不同，因为当下运行的进程可能和中断完全无关。中断可以分为：I/O中断、时钟中断、处理器间中断。这里，以I/O中断为例。I/O中断必须能够为多个设备同时提供服务，而多个设备却可能会共享一个IRQ线。它往往包含四个部分：（1）在内核态堆栈中保存IRQ的值和寄存器的内容；（2）给为IRQ服务的PIC发一个应答，允许PIC进一步发出中断；（3）执行共享这个IRQ的所有设备的中断服务历程（<code>do_IRQ()</code>会执行与一个中断相关的所有中断服务历程，并且验证它的设备是否需要关注，这也与驱动注册相关）；（4）跳转到<code>ret_from_inrt()</code>后终止。<br>IRQ的动态分配：IRQ线可能在最后时刻才和一个设备驱动相关联，这样即使几个硬件设备不共享IRQ，也能够让几个设备在不同时刻使用同一个IRQ向量。  </p>
<h4 id="处理器间的中断（IPI）"><a href="#处理器间的中断（IPI）" class="headerlink" title="处理器间的中断（IPI）"></a>处理器间的中断（IPI）</h4><p>由某个CPU向系统中的其他CPU发送中断信号，它不由IRQ总线，而是由本地APIC的总线传递。Linux定义了这样几种处理器间中断。<br>CALL_FUNCTION：强制所有剩余CPU执行发送者传递过来的函数<br>RESCHEDULE_VECTOR：让被中断的CPU重新调度<br>INVALIDATE_TLB_VECTOR：强制CPU清洗TLB  </p>
<h4 id="软中断和tasklet"><a href="#软中断和tasklet" class="headerlink" title="软中断和tasklet"></a>软中断和tasklet</h4><p>软中断是一种提高运行效率的手段，其核心思想是把不紧迫懂、可以延时处理的中断部分，在中断上下文外，由操作系统自行安排运行时机来运行。tasklet则是建立在软中断之上来实现的，它是I/O驱动中实现可延迟函数的主要方法。对于挂起的软中断，内核会用<code>ksoftirqd</code>进行检查和运行。  </p>
<h4 id="工作队列"><a href="#工作队列" class="headerlink" title="工作队列"></a>工作队列</h4><p>工作队列是内核中，另外一种将工作推后的形式。其特点在于，它允许<strong>重新调度</strong>和<strong>睡眠</strong>。其本质就是将工作交给内核线程处理。如果推后执行的任务需要睡眠、或者延时指定的时间再触发，则使用这种形式比较好；倘若推后的任务需要在一个tick内处理，那么还是选择软中断或者tasklet的形式比较好。  </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/03/06/中断的发生/" data-id="cj5nn6mlr0031o43fvcybwsxf" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/linux/">linux</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/操作系统/">操作系统</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-中断相关" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/02/15/中断相关/" class="article-date">
  <time datetime="2017-02-15T13:40:00.000Z" itemprop="datePublished">2017-02-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/02/15/中断相关/">深入理解中断（一）</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="什么是中断？"><a href="#什么是中断？" class="headerlink" title="什么是中断？"></a>什么是中断？</h3><p>中断是能够打断CPU指令序列的事件，它是在CPU内外，由硬件产生的电信号。CPU接收到中断后，就会向OS反映这个信号，从而由OS就会对新到来的数据进行处理。不同的事件，其对应的中断不同，而OS则是通过<strong>中断号</strong>(也即IRQ线)来找到对应的处理方法。不同体系中，中断可能是固定好的，也可能是动态分配的。<br>中断产生后，首先会告诉中断控制器。中断控制器负责收集所有中断源的中断，它能够控制中断源的优先级、中断的类型，指定中断发给哪一个CPU处理。<br>中断控制器通知CPU后，对于一个中断，会有一个CPU来响应这个中断请求。CPU会暂停正在执行的程序，转而去执行相应的处理程序，也即OS当中的中断处理程序。这里，中断处理程序是和特定的中断相关联的。  </p>
<h3 id="中断描述符表"><a href="#中断描述符表" class="headerlink" title="中断描述符表"></a>中断描述符表</h3><p>那么CPU是如何找到中断服务程序的呢？为了让CPU由中断号去查找到对应的中断程序入口，就需要在内存中建立一张查询表，也即中断描述符(IDT)。在CPU当中，有专门的寄存器IDTR来保存IDT在内存中的位置。这里需要注意的是，常说的中断向量表，是在实模式下的，中断向量是直接指出处理过程的入口，而中断描述符表除了入口地址还有别的信息。<br>IDTR有48位，前32位保存了IDT在内存中的线性地址，后16位则是保存IDT的大小。而IDT自身，则是一个最大为256项的表（对应了8位的中断码），表中的每个向量，是一个入口。这里IDT表项的异常类型可以分为三种，其表项的格式也不同：<br>任务门：利用新的任务方式去处理，需要切换TSS。它包含有一个进程的TSS段选择符，其偏移量部分没有用，linux没有采用它来进行任务切换。<br>中断门：适宜处理中断，在进入中断处理时，处理器会清IF标志，避免嵌套中断发生。中断门中的DPL(Descriptor privilege Level)为0，因此用户态不能访问中断门，中断处理程序都是用中断门来激活的，并且限制在内核态。<br>陷阱门：适宜处理异常，和中断门类似，但它不会屏蔽中断。<br>以下是<strong>32bit</strong>中的IDT表项。<br><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/%E4%B8%AD%E6%96%AD/IDT%E9%97%A8.gif?raw=true" alt="IDT门"><br>值得注意的是，CPU还提供一种门，<strong>调用门</strong>，它是linux内核特别设置的，通常通过CALL和JMP指令来使用，能够转移特权级。</p>
<h3 id="实模式和保护模式"><a href="#实模式和保护模式" class="headerlink" title="实模式和保护模式"></a>实模式和保护模式</h3><p>在了解CPU是如何通过中断向量表调用具体的服务程序之前，首先需要了解CPU的工作方式。<br>对于IA-32架构，它支持实模式、保护模式和系统管理模式。<br><strong>实模式</strong>以拓展对方式实现了8086CPU的程序运行环境，处理器在刚刚上电和重启后时，处于实模式，其寻址空间最大为1M(2^20)。实模式的主要意义，在于提供更好的兼容性，开发者能够直接使用BIOS中断，从而在boot阶段不必关注硬件的具体实现。实模式主要还是为进入保护模式进行准备。<br>8086处理器有16-bit寄存器和16-bit的外部数据总线，但能够访问20-bit的地址，因为它引入了“分段机制”，一个16bit的段寄存器包含了一个64KB的段的基址。而段寄存器＋16bit的指针，就能够提供20bits的地址空间。其计算方式为：16位基地址左移4位＋16位偏移量＝20位。<br><strong>保护模式</strong>是处理器的根本模式。保护模式可以直接为实模式程序提供保护的，多任务的环境，这种特性被称为虚拟8086模式，它实际上是保护模式的一种属性。保护模式能够为任何任务提供这种属性。在保护模式中，地址依然通过“段＋偏移量”的形式来实现，但此时段寄存器中保存的不再是一个段的基址，而是一个索引。通过这个索引可以找到一个表项，里面存放了段基址等许多属性，这个表项也就是段描述符，而这个表也就是GDT表。<br>保护模式的最大寻址是2^32次方，也即4G，并且可以通过PAE模式访问超过4G的部分。它有4个安全级别，内存操作时，有安全检查。其分页功能带来了虚拟地址和物理地址的区别。<br><strong>系统管理模式</strong>为操作系统或者执行程序提供透明的机制去实现平台相关的特性，例如电源管理、系统安全。<br>对于Intel 64架构，它增加了两种子模式。<br><strong>兼容模式</strong>允许绝大部分16bit-32bit应用无需编译就能在64bit下运行，它类似于保护模式，有4G的地址空间限制。<br><strong>64bit模式</strong>在64bit线性地址空间上运行应用程序，通用寄存器被增加到64bits。它取消了分段机制，其默认地址长度为64bits。</p>
<h3 id="x64寻址"><a href="#x64寻址" class="headerlink" title="x64寻址"></a>x64寻址</h3><p>在保护模式下(32bit)，物理地址的翻译分为两步：逻辑地址翻译(段)和线性地址翻译(页)。逻辑地址利用16bit segment selector和32bit offset来表示。处理器首先要将逻辑地址翻译为线性地址(32bit)。这个翻译过程如下：  </p>
<ol>
<li>通过segment selector，在对应的GDT或LDT中去找到段描述符；  </li>
<li>检查段描述符，访问是否合法，段是否能够访问，偏移量是否在范围之内；   </li>
<li>将段基地址和偏移量相加来获取线性地址的值。  </li>
</ol>
<p>在IA-32e模式下(64bit)，逻辑地址的翻译步骤和上述过程类似，唯一不同的是，其段基地址和偏移量，都是64bit，而不是32bit的。线性地址同理也是32bit的。  </p>
<p>段寻址，也即将内存分成不同的段，利用段寄存器能够找到其对应的段描述符，从而获得相关的段基址、大小、权限等信息。<br><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/%E4%B8%AD%E6%96%AD/%E6%AE%B5%E5%AF%BB%E5%9D%80.png?raw=true" alt="段寻址"><br>段选择子Segment selector的示意图如下：<br><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/%E4%B8%AD%E6%96%AD/%E6%AE%B5%E9%80%89%E6%8B%A9%E5%AD%90.png?raw=true" alt="段选择子"><br>段选择子会被存在段寄存器当中，其中最低两位为RPL(cs寄存器不同，最低位位CPL)。而第三位Table Indicator则是表示该从GDT还是LDT寻找对应的段描述符，后面的bits就是对应的index了。<br>为了减少地址翻译的开销，处理器提供了6个段寄存器，CS，SS，DS，ES，FS，GS。通常来说一个程序至少有CS、DS、SS三个selector。假设程序要使用段来访问地址，那么必须将segment selector载入段寄存器当中。对此，Intel是提供了特殊的指令的，直接载入的指令包括MOV，POP，LDS，LES等。而隐含的载入则包括CALL，JMP，RET，SYSENTER等等。它们会改变CS寄存器(有时也会改变其它段寄存器)的内容。  </p>
<p>而在IA-32e模式下(64bit mode)，ES，DS，SS段寄存器都不会使用了，因此它们的域会被忽视掉，而且某些load指令也被视为违法的，例如LDS。与ES，DS，SS段有关的地址计算，会被视为segment base为0。为了保证兼容性，在64bit mode当中，段load指令会正常执行，从GDT、LDT中读取时，也会读取寄存器的隐藏部分，并且值都会正常的载入。但是data、stack的segment selector和描述符都会被忽略掉。<br>而FS和GS段在64bit mode能够手动使用，它们的计算方式为(FS/GS).base+index+displacement。用这种方式去进行内存访问时，是不会进行检查的。载入的时候不会载入Visible Part，也即Segment Selector，也就是把段机制给忽略了。</p>
<h3 id="IDT，LDT和GDT"><a href="#IDT，LDT和GDT" class="headerlink" title="IDT，LDT和GDT"></a>IDT，LDT和GDT</h3><p>中断向量表提供了一个入口，但这个入口还需要进一步的计算。这个入口的计算，是通过段寻址来实现的。而段的信息，则是保存在LDT和GDT当中。<br>段描述符的结构如下图：<br><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/%E4%B8%AD%E6%96%AD/%E6%AE%B5%E6%8F%8F%E8%BF%B0%E7%AC%A6.png?raw=true" alt="段描述符"><br>段描述符最重要的部分是DPL位，它会在权限检查的时候使用。在进程需要装载一个新的段选择子时，会判断当前的CPL和RPL是否都比相应的DPL权限高，如果是则允许加载新的段选择子，否则产生GP。<br>在操作系统中，全局描述符只有一张，也即一个CPU对应一个GDT。GDT可以存放在内存中的任何地址，但CPU必须知道GDT的入口，因此有一个寄存器GDTR用来存放GDT的入口地址，它存放了GDT在内存中的基址和表长。<br><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/%E4%B8%AD%E6%96%AD/GDT&amp;LDT.png?raw=true" alt="GDT&amp;LDT"><br>但是在64位系统当中，段机制就被取代了，而页表项也能够达到数据访问的保护目的。但是对于不同特权级之间的控制流转移，还是和原来的机制一样。在64-bit模式中，GDT依然存在，但不会改变，而其寄存器被拓展到了80bit。<br>而GDT中会包含一个LDT段的段描述符，LDT是通过它的段描述符来访问的。  </p>
<p>在IA-32e模式下，段描述符表可以包含2^13个8-byte描述符。这里，描述符分为两种，段描述符会占据一个entry(8bit)，而系统描述符会占据两个entry(16bit)。而GDTR和LDTR被拓展为能够保存64bit的基地址。其中，IDT描述符、LDT、TSS描述符和调用门描述符都被拓展称为了16bytes。</p>
<p>64bit IDT描述符的格式如下  </p>
<p><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/%E4%B8%AD%E6%96%AD/64bitIDT.png?raw=true" alt="64bit IDT"></p>
<p>64bit LDT描述符的格式如下  </p>
<p><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/%E4%B8%AD%E6%96%AD/64bitLDT.png?raw=true" alt="64 bit LDT"></p>
<h3 id="中断的处理过程"><a href="#中断的处理过程" class="headerlink" title="中断的处理过程"></a>中断的处理过程</h3><p>在intel 手册上看到的大图，很详细的解释了IA-32模式和IA-32e模式下的系统架构，它也就包含了中断处理和线性地址的翻译过程。<br><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/%E4%B8%AD%E6%96%AD/IA-32.png?raw=true" alt="IA-32"><br><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/%E4%B8%AD%E6%96%AD/IA-32e.png?raw=true" alt="IA-32e"><br>在中断产生之后，处理器会将中断向量号作为索引，在IDT表中找到对应的处理程序。IDT表将每个中断/异常向量和一个门描述符关联起来。在保护模式下，它是一个8-byte的描述符（与GDT，LDT类似），IDT最大有256项。IDT能够保存在内存中的任何位置，处理器用IDTR寄存器来保存它的值。<br>在中断/陷阱门描述符中，segment selector指向了GDT或当前LDT中的代码段描述符，而offser域指向了exception/interrupt的处理过程。<br><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/%E4%B8%AD%E6%96%AD/Int.png?raw=true" alt="IA-32e"><br>在执行call这一步的时候，倘若handler过程会在一个更低的权限执行，那么就会涉及到stack switch。当stack switch发生时，segment selector和新的栈指针都需要通过TSS来获取，在这个栈上，处理器会把之前的segment selector和栈指针压入栈中。处理器还将保存当前的状态寄存器在新的栈上。<br>如果handler过程会在相同的权限执行，处理器会把状态寄存器的值保存在当前的栈上。<br><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/%E4%B8%AD%E6%96%AD/Stackswitch.png?raw=true" alt="IA-32e"><br>从中断处理程序返回时，handler必须使用IRET指令。它与RET类似，但它会将保存的标志位恢复到EFLAGS寄存器中。如果stack switch在调用过程中发生了那么IRET会切换到中断前的stack上。在中断过程中，权限级的保护与CALL调用过程类似，会对CPL进行检查。</p>
<h3 id="64-bit模式下的中断处理"><a href="#64-bit模式下的中断处理" class="headerlink" title="64-bit模式下的中断处理"></a>64-bit模式下的中断处理</h3><p>在64bit模式下，中断和异常的处理与非64bit模式下几本一致，但也存在一些不同的地方。包括有：</p>
<ul>
<li>IDT所指向的代码是64bit代码  </li>
<li>中断栈push的大小是64bit  </li>
<li>栈指针(SS:RSP)在中断时，无条件的被push（保护模式下是由CPL来决定的） </li>
<li>当CPL有变化时，新的SS会被设置为NULL  </li>
<li>IRET的过程不同  </li>
<li>stack-switch的机制不同</li>
<li>中断stack的对齐不同  </li>
</ul>
<p>其中，64bit的IDT门描述符在前面已经介绍了。IST（interrupt Stack Table）用于stack-switch。通过中断门来调用目标代码段时，它必须为一个64bit的代码段(CS.L=1,CS.D=0)。如果不是也会触发#GP。在IA-32e模式下，只有64bit的中断和陷阱门能够被调用，遗留的32bit中断/陷阱都被重新定义为64bit的。  </p>
<p>在遗留模式中，IDT entry的大小是16/32bit，它决定了interrupt-stack-frame push时的大小。并且SS:ESP只在CPL发生改变时被压入stack中。在64bit模式下，interrupt-stack-frame push的大小被固定为8bytes(因为只有64bit模式的门能够被调用)，而且SS:RSP是无条件压入栈中的。遗留模式下，Stack pointer能够在任何地址进行push，但是IA-32e模式之下，RSP必须是16-byte边界对齐的，而stack frame在中断处理程序被调用时也会对齐。而在中断服务结束时，IRET也会无条件的POP出SS:RSP，即使CPL=0。  </p>
<p>IA-32e模式下，stack-switching机制被替代了，它被称为interrupt stack table(IST)。<br>遗留模式下，在64bit中，中断如果造成了权限级的改变，那么stack就会switch，但是这时不会载入新的SS描述符，而只会从TSS中载入一个inner-level的RSP。新的SS selector被强制设置为NULL，这样就能够处理内嵌的far transfers。而旧的SS和RSP会被保存在新的栈上。也就是说stack-switch机制除了SS selector不会从TSS加载之外，其余都一样。<br>而新的IST模式，则是无条件的进行stack switch。它是基于IDT表项中的一块区域实现的，它的设计目的，是为特殊的中断(NMI、double-fault、machine-check)等提供方法。在IA-32e模式下，一部分中断向量能够使用IST，另一部分能够使用遗留的方法。<br>IST在TSS中，提供7个IST指针，在中断门的描述符当中，由一个3bit的IST索引位，它们用来找到TSS中IST的偏移量。通过这个机制，处理器将IST所指向的值加载到RSP当中。而当中断发生时，新的SS selector被设置为NULL，并且SS selector的RPL区域被设置为新的CPL。旧的SS、RSP、RFLAGS、CS和RIP被push入新的栈中。如果IST的索引为0，那么就会使用修改后的、旧的stack-switch机制。 </p>
<h3 id="保护机制"><a href="#保护机制" class="headerlink" title="保护机制"></a>保护机制</h3><p>Intel 64/IA-32架构提供了段/页级别的保护机制，它们利用权限级，来限制对于的段/页的访问，例如重要的OS代码和数据能够被放在更高权限级的段中，操作系统会保护它们不被应用程序访问。当保护机制启用时，每次内存访问都会被检查，这些检查包括：</p>
<ul>
<li>Limit</li>
<li>Tyep</li>
<li>Privilege level</li>
<li>Restriction of Procedure entry-points</li>
<li>Restriction of instruction set</li>
</ul>
<p>通过CR0寄存器当中的PE flag能够开启保护模式，打开段保护机制；而页保护机制则是在分页机制启用时，自动开启的。虽然64bit中，不再使用分段机制了，但<strong>代码段</strong>依然存在。对于地址计算来说，其段地址被视为0，CS描述符当中的内容被忽略，但其余部分保持一致。代码段描述符、selector依然存在，它们在处理器的操作模式、执行权限级上依然发挥作用。其工作方式如下：</p>
<p>CS描述符中会使用一个保留位，Bit 53被定义为64 bit flag位(L)，并且被用来在64bit/兼容模式之间切换。当CS.L ＝ 0时，CPU处于兼容模式，CS.D则决定了数据和地址的位数为16/32bit。如果CS.L为1，那么只有CS.D = 1是合法的，并且地址和数据的位数是64bit。在IA-32e模式下，CS描述符当中的DPL位被用来做执行权限的检查(与32bit模式一样)。<br><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/%E4%B8%AD%E6%96%AD/%E4%BB%A3%E7%A0%81%E6%AE%B5.png?raw=true" alt="代码段">  </p>
<h5 id="Limit-Checking"><a href="#Limit-Checking" class="headerlink" title="Limit Checking"></a>Limit Checking</h5><p>在段描述符当中，有一个limit field，它防止程序访问某个段之外的的内存位置，其有效值由G flag来决定，对于数据段来说，其limit还由E flag和B flag决定。在64bit模式下，处理器不会对代码段活着数据段进行limit check，但是会对<strong>描述符表</strong>的limit进行检查。  </p>
<h5 id="Type-checking"><a href="#Type-checking" class="headerlink" title="Type checking"></a>Type checking</h5><p>段描述符包含两个type 信息，S flag和type field。处理器会使用这个信息，来检查对段和门的不正确使用。S flag表示descriptor的类型，它包括系统/代码/数据三种类型。在处理一个段选择子时，处理器会在：<br>将segment selector载入段寄存器：寄存器只能包含对应的描述符类型<br>指令访问段时：段只能被相应的指令访问<br>指令包含segment selector时：指令只能对某些特定类型的段/门进行访问<br>进行某些具体操作时：far call、far jump，对调用门、任务门的call/jump等，会判断描述符中的类型是否符合要求。</p>
<h5 id="Privilege-levels"><a href="#Privilege-levels" class="headerlink" title="Privilege levels"></a>Privilege levels</h5><p>处理器的段保护机制包含有4个privilege levels，从0到3，0最高，3最低。处理器利用这种机制，来防止一个低权限的进程，访问更高权限的部分。为了实现这个目的，处理器使用3种类型的权限级：<br>CPL：当前执行任务的权限级。它保存在CS和SS段寄存器的bit 0-1中。通常，CPL和当前代码段的权限一致，当跳转到一个有不同权限的代码段时，CPL会发生变化。如果目标是一致代码段，则会延续当前的CPL。<br>DPL：segment或者gate的权限级。它保存在段或者门的描述符当中，当当前的代码段执行，需要访问一个段或者gate的时候，这个段/门的DPL就会被拿来与CPL和RPL进行比较。在不同的环境下，DPL的意义也是不同的。<br>RPL：与segment selector有关的，能够对权限进行覆盖的权限级。它保存在segment selector的bit 0-1中。处理器会通过CPL和RPL来判断对segment的访问是否合法。即使请求访问某个段的程序，拥有比段更高的权限，如果RPL不是有效的，访问还是会被拒绝。也就是说如果RPL把CPL高，那么RPL会覆盖CPL。RPL能够保证提权的代码，不能随意访问一个segment段，除非它自身有这个权限。直观的说，必须CPL和RPL都比DPL要高，只有这种情况下，才会允许这个段的访问。其主要目的，是允许高权限为低权限提供服务的时候，能够通过较低的权限来加载段。<br>门调用符与权限检查：<br><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/%E4%B8%AD%E6%96%AD/gate.png?raw=true" alt="gate">  </p>
<h3 id="TSS"><a href="#TSS" class="headerlink" title="TSS"></a>TSS</h3><p>处理器执行工作的单位，被称为task。一个task分为两个部分，task的执行空间和task-state segment(TSS)。前者指的是code/stack/data segment，而后者则定义了组成前者的各个段。task是由TSS的segment selector来识别的。当一个任务被加载到处理器中执行时，segment selector、基址、limit、TSS的段描述符等都会被加载到<strong>task register(TR)</strong>当中去。分页启动时，页目录的基址还会载入到控制寄存器CR3当中去。<br>一个任务的状态，由一系列的寄存器和TSS来定义。这里，处理器定义了5个数据结构，来处理任务相关的活动。  </p>
<ul>
<li>TSS</li>
<li>Task-gate描述符</li>
<li>TSS描述符</li>
<li>Task寄存器  </li>
<li>EFLAGS寄存器中的NT flag</li>
</ul>
<p>为了恢复一个task，处理器所需要的信息，保存在一个系统段中，它被称为TSS。在64bit模式下，它的格式如下：</p>
<p><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/%E4%B8%AD%E6%96%AD/64bitTSS.png?raw=true" alt="gate">  </p>
<p>而TSS描述符，则和其他的段一样，是由一个段描述符来定义的，它的结构在上文中已经给出了（与LDT是一致的），它只能放在GDT当中，不能放在LDT或者IDT当中。  </p>
<p>Task寄存器保存了当前TSS的段选择子和整个段描述符。它包含可见和不可见两个部分（能否被软件修改）。段选择子位于可见部分，指向GDT当中的TSS描述符。不可见部分则是用来保存TSS的段描述符（能够提高执行效率）。  </p>
<p><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/%E4%B8%AD%E6%96%AD/TaskRegister.png?raw=true" alt="gate">  </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/02/15/中断相关/" data-id="cj5nn6mls0034o43fjddloyms" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/linux/">linux</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/操作系统/">操作系统</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/系统安全/">系统安全</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-kvm-sgx笔记" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/01/17/kvm-sgx笔记/" class="article-date">
  <time datetime="2017-01-17T04:00:00.000Z" itemprop="datePublished">2017-01-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/01/17/kvm-sgx笔记/">SGX虚拟化相关</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="KVM-SGX"><a href="#KVM-SGX" class="headerlink" title="KVM-SGX"></a>KVM-SGX</h3><p>虚拟机中的epc，使用sgx_vm_epc_buffer结构来管理的。其数据结构如下：  </p>
<pre><code>  struct sgx_vm_epc_buffer {
    struct list_head buf_list;
    struct list_head page_list;
    unsigned int nr_pages;
    unsigned long userspace_addr;
    __u32 handle;
};
</code></pre><p>Kai Huang添加了sgx_vm.c。</p>
<pre><code>__alloc_epc_buf:申请一个新的epc buffer，在这里对每一个页，都申请了一个iso_page。它调用sgx_alloc_vm_epc_page来完成具体的申请。这个函数定义在sgx_alloc_epc_page当中，实际上调用的就是sgx_alloc_epc_page。

__get_next_epc_buf_handle():每一个epc buffer都有一个handle，这个handle相当于一个标识，利用handle来找到对应的epc buffer，这个函数用来在申请一个epc_buf的时候，获取它的handle。  

__free_epc_buf():释放epc buffer，这里同样也要完成对应的iso_pages的释放。  

__sgx_map_vm_epc_buffer():按页实际完成按页的映射，它调用了vm_insert_pfn函数。它进而调用vm_insert_pfn_prot，这个函数位于mm/memory.c中，也即完成一个页的映射(pfn to pfn)。
</code></pre><p>在kvm_main.c中，hva_to_pfn函数被进行了修改，这是为了让pfn的映射，支持到EPC这一段内存，而epc并不是连续的，所以需要从页表中搜索到pfn。hva_to_pfn()，其参数address为host virtual address，通过一个guest页的hva，来找到对应的pfn。它调用了follow_pfn(使用user virtual address来查找一个页框)。</p>
<pre><code>只有在hva_to_pfn_fast/hva_to_pfn_slow都无法找到pfn时，才会使用这种方法。因为EPC不是连续的内存段，所以会用这种方法特殊处理。
</code></pre><p>arch/x86/kvm/vmx.h/vmx.c中，做了VMX和SGX交互的修改。</p>
<pre><code>首先对于一部分enclave中不允许使用的指令，例如CPUID，INVD，做了#GP处理。

vmx_exit_from_enclave():enclave中发生了VMEXIT的情况。这里使用了VM_EXIT_REASON的bit 27和GUEST_INTERRUPTIBILITY_INFO中的bit 4来表示VMEXIT的原因。

vmx_handle_exit是对exit的具体处理。利用VM_EXIT_REASON的bit 27，可以判断这个exit是在enclave当中发生的。这个函数确定exit的类型，再交由对应的handler进行处理。
</code></pre><h3 id="QEMU-SGX"><a href="#QEMU-SGX" class="headerlink" title="QEMU-SGX"></a>QEMU-SGX</h3><p>在target-i386/kvm.c当中，qemu首先为isgx定义了一个设备node:/dev/sgx，并且定义了VM中SGX的状态SGXState。在kvm.c中，定义了epc的alloc、free</p>
<pre><code>#define SGX_IOC_ALLOC_VM_EPC  _IOWR(SGX_MAGIC, 0x03, struct sgx_alloc_vm_epc)
#define SGX_IOC_FREE_VM_EPC  _IOW(SGX_MAGIC, 0x04, struct sgx_free_vm_epc)
</code></pre><p>这两个宏定义，最后交给了struct中对应的handle来处理，也即ISGX驱动中对应的函数。而qemu内部的接口则是kvm_alloc_epc/kvm_free_vm_epc。kvm.c中，还定义了epc的初始化和销毁。epc的计算是在vcpus创建之前完成的，这里epc的大小被限制在256M之内，它被放置在below_4g_memory_size的位置，位于PCI的基址之下。在target-i386/cpu.c中，添加了对cpuid对应功能的支持。  在/hw/i386/acpi-build.c当中，添加了EPC的ACPI table项。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/01/17/kvm-sgx笔记/" data-id="cj5nn6mkp001zo43fm71wcrk0" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/KVM/">KVM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/QEMU/">QEMU</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SGX/">SGX</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Chrome浏览器安全" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/27/Chrome浏览器安全/" class="article-date">
  <time datetime="2016-12-27T13:00:00.000Z" itemprop="datePublished">2016-12-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/27/Chrome浏览器安全/">Chrome隔离/SOP策略</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h5 id="The-“Web-Local”-Boundary-is-Fuzzy"><a href="#The-“Web-Local”-Boundary-is-Fuzzy" class="headerlink" title="The “Web/Local” Boundary is Fuzzy"></a>The “Web/Local” Boundary is Fuzzy</h5><p>Process-based隔离，是浏览器安全的基础。Chrome的设计，并不隔离每个web源，而是主要保证“本地系统”和“web”，但是由于Dropbox，Google Drive这样的web端云服务(这些服务和本地系统一体化了)，浏览器不再能保证web和本地系统的隔离了。这篇文章提出了chrome中存在的一个问题，如果process-based隔离，忽略了同源策略，那么就很难保证web/local隔离的有效性。<br>这篇文章提出，利用renderer中存在的漏洞，能够将可执行文件、脚本存放到本地文件系统中，肆意安装应用，滥用传感器等。这个攻击也是一个完全data-oriented的攻击，它不需要去劫持程序的控制流，或者引入外部代码。  </p>
<h4 id="浏览器隔离保护技术"><a href="#浏览器隔离保护技术" class="headerlink" title="浏览器隔离保护技术"></a>浏览器隔离保护技术</h4><p>web浏览器，在对象、资源的划分上，一直存在漏洞，这也导致一个binary-level的漏洞，能够让攻击者劫持整个browser。为了对抗这些恶意的网站，现代的浏览器架构，普遍应用了sandbox技术来加强web域和local域之间的隔离。sandbox保证，即使浏览器中出现了memory errors，也不会影响到本地的系统。在此之上，现代浏览器还采用了process隔离的设计。这个设计的目标，是进一步将exploit的影响限制在边界之内，这样其它进程就不会受到影响。Google chrome和IE都应用了这种设计。<br>Goolge chrome从两方面进行了隔离：其一是将浏览器的kernel process和renderer process隔离；其二是将website或tabs，划分到不同的renderer process当中去。为了对性能进行提升，chrome降低了sandbox的粒度，放弃了SOP(同源策略)。SOP的任务完全交给了renderer来承担。  </p>
<h4 id="chrome-web-local隔离"><a href="#chrome-web-local隔离" class="headerlink" title="chrome web/local隔离"></a>chrome web/local隔离</h4><p>chrome中，进程分为两类： </p>
<ol>
<li>kernel，用来和本地系统交互；  </li>
<li>renderer，负责显示网页。  </li>
</ol>
<p>kernel process，负责网络请求，访问cookies，显示bitmaps；而renderer process则负责解释web文件(html，ccs，js)。每个renderer process都被限制在一个sandbox中，也只能通过kernel process来访问有限的资源。<br>chrome的sandbox技术，是借助于操作系统的。例如在Linux当中，Chrome有两层sandbox，第一层为不同的renderer process创建不同的PID namespaces和网络资源；第二层保护browser kernel不受用户空间中恶意代码的影响。因此renderers只能通过IPC call，通过kernel来访问有限的资源。  </p>
<h4 id="chrome-SOP策略"><a href="#chrome-SOP策略" class="headerlink" title="chrome SOP策略"></a>chrome SOP策略</h4><p>在chrome中，SOP是由renderer process来全权负责的。它负责脚本只能在同源时，跨站进行访问。<br>例如途中，当A的脚本访问B中对象时，首先要通过security monitor进行检查。<br><img src="https://github.com/lbxl2345/blogbackup/blob/master/source/pics/%E6%B5%8F%E8%A7%88%E5%99%A8/chrome-SOP.png?raw=true" alt="chrome-SOP"><br>对于process内部，chrome将无关的数据放置在不同的区域中。例如，对每个renderer，其heap都是分隔开的，chrome随机化每个部分的起始地址，并用guardpages进行保护。</p>
<h4 id="绕过chrome-SOP"><a href="#绕过chrome-SOP" class="headerlink" title="绕过chrome SOP"></a>绕过chrome SOP</h4><p>Google chrome采用了共享一个renderer process的架构，因此SOP检查必须放在同一个security monitor，它位于renderer进程中。如果能够篡改monitor中的关键数据，就能够绕过SOP，在A中获得B的权限来执行任意代码。<br>在chrome中，security monitor是由一系列的函数调用来实现的。在内存中，保存了大量的flags、以及SOP检查的记过。而从A，或者B中，均能够对这些数据区域进行访问。在chrome当中，甚至还有能够对全局进行访问的标志位。</p>
<pre><code>bool SecurityOrigin::canAccess(const SecurityOrigin*
 other) const
{
    ￼if (m_universalAccess) return true;
    if (this == other) return true;
    if (isUnique() || other-&gt;isUnique()) return false;
    return canAccess; 
}
</code></pre><p>而利用系统中的漏洞，对这些critical data进行修改，就能够实现肆意的访问、执行。<br>攻击的第一步，是绕过ASLR。在攻击者的脚本中，是能够创建一个layout形式可以预测的object的。攻击者通过线性的扫描，是能够确认object的位置的。而这个object位置，就揭露了随机化的地址。<br>第二步，是绕过浏览器内部的隔离。这里，chrome采用的是一种in-memory的隔离方式，也就是将无关的数据放在分隔的部分中去。这里，不同的隔离区被guard pages保护了，并且其位置也是随机化的。然而，通过利用指针，进行跨隔离区的引用，也能够识别出隔离区内的地址。  </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/27/Chrome浏览器安全/" data-id="cj5nn6mjs0015o43f4hkfps39" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/chrome/">chrome</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/浏览器安全/">浏览器安全</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-memory-war" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/05/memory-war/" class="article-date">
  <time datetime="2016-12-05T09:40:00.000Z" itemprop="datePublished">2016-12-05</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/05/memory-war/">内存攻击与保护</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h4 id="memory-corruption"><a href="#memory-corruption" class="headerlink" title="memory corruption"></a>memory corruption</h4><p>Step 1: 一个指针变成非法的指针<br>第一种:越过它所引用的对象的边界(out-of-bounds pointer)，<strong>spatial error</strong><br>第二种:它所指向的对象已经被释放(dangling pointer)，<strong>temporal error</strong>  </p>
<hr>
<p><strong>Bugs lead to Out-of-bounds:</strong>  </p>
<ol>
<li>allocation failure –&gt; null pointer  </li>
<li>过多的增／减 array pointer –&gt; buffer overflow/underflow  </li>
<li>indexing bugs –&gt; pointer 指向任意位置</li>
</ol>
<p>Bugs lead to dangling:<br>objects释放了，但指向它的指针没有释放<br>(大多数objects在堆上，但堆栈上多objects如果用了全局的pointer，也会出现dangling pointer)   </p>
<hr>
<p>Step 2: dereferences the pointer<br>dereferences the pointer: 读/写  </p>
<hr>
<p>Step 3: corruption/leakage of data<br><strong>Out-Of-Bounds</strong><br>1 read from memory<br>pointer指向了攻击者控制的位置，那么取的值就被攻击者操纵了</p>
<pre><code>- 指针指向控制相关的数据，现在攻击者将它指向了恶意的转移目标 --&gt; divert control-flow
- 指针指向输出数据，现在攻击者将它指向了一些隐私数据 --&gt; leaks information  
</code></pre><p>2 write to memory<br>pointer指向写的地址，那么攻击者就能够篡改内存中的任意数据  </p>
<pre><code>- 篡改一个控制相关的变量，例如vtable，返回地址 --&gt; divert control-flow  
- 篡改一个输出的地址(另一个指针) --&gt; leaks information  
</code></pre><p><strong>Dangling  pointer</strong><br>由deallocated object释放的memory，会被另一个object重新使用，而两种object的type是不同的，因此新的object会被解释为旧的object。<br>1 read from memory<br>旧的object的vpointer –&gt;  divert control-flow<br>新的object中敏感数据可用旧的object输出 –&gt; leaks information<br>2 write to memory<br>旧的object在栈上 –&gt;  divert control-flow(return address)<br>double-free leads to double-alloc –&gt; arbitraty wirtes  </p>
<hr>
<h4 id="attack-type"><a href="#attack-type" class="headerlink" title="attack type"></a>attack type</h4><p><strong>控制流劫持</strong>:divert control-flow<br><strong>data-only攻击</strong>:gain more control,gain privileges<br><strong>Information leak</strong>：leaks information  </p>
<hr>
<h4 id="Protections"><a href="#Protections" class="headerlink" title="Protections"></a>Protections</h4><p>Probabilistic: Randomization/encryption<br>Deterministic: Memory Safety/Control-flow Integrity<br>其中Deterministic protections又可以分为hardware/software两种<br>其中，software的方法，可以通过静态/动态两种插桩方式来实现。  </p>
<h5 id="Probabilitic-Methods"><a href="#Probabilitic-Methods" class="headerlink" title="Probabilitic Methods"></a>Probabilitic Methods</h5><p>Probabilitic Method依赖于随机化，包括有:<br>Address Space Randomization:代码和数据段的位置，在W⊕X后，主要应用于code<br>Data Space Randomization:对所有的变量进行加密  </p>
<h5 id="Deterministic-Methods"><a href="#Deterministic-Methods" class="headerlink" title="Deterministic Methods"></a>Deterministic Methods</h5><p><strong>Memory Safety</strong><br>空间安全-指针边界:指针能指向的地址范围<br>空间安全-对象边界:对象的地址范围，比指针边界的兼容性更好<br>时序安全-特殊的allocators:申请内存时避免use-after-free，例如只使用相同类型的memory<br>时序安全-基于对象:在shadow memory中标记释放内存，但如果这段内存被重新申请则无效<br>时序安全-基于指针:在内存释放/申请时，更新指针信息  </p>
<h4 id="Generic-Attatck-Defenses"><a href="#Generic-Attatck-Defenses" class="headerlink" title="Generic Attatck Defenses"></a>Generic Attatck Defenses</h4><p><strong>Data Integrity</strong><br>不关注时序安全，只保护memory写，不保护memory读。<br>safe objects integrity:分析出不安全的指针和对象，利用shadow memory记录对应关系<br>points-to sets integrity:分析出不安全的指针和对象，限制其points-to set的对应关系<br><strong>Data-Flow Integrity</strong><br>通过检查read指令，检测任何数据的corruption(上一次write是否合法)，同样使用ID和set的方式。  </p>
<h4 id="Control-Flow-Hijack-Defenses"><a href="#Control-Flow-Hijack-Defenses" class="headerlink" title="Control-Flow Hijack Defenses"></a>Control-Flow Hijack Defenses</h4><p><strong>Code Pointer Integrity</strong><br>防止Code Pointer被篡改，例如对Code pointer进行加密等。<br><strong>Control Flow Integrity</strong><br>动态return integrity:对返回值进行保护，如shadow stacks。<br>static CFI:求出控制流转移的集合，在运行时检查控制流转移是否合法。  </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/05/memory-war/" data-id="cj5nn6ml8002co43fddkikw9z" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/二进制/">二进制</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/底层安全/">底层安全</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <a class="extend prev" rel="prev" href="/page/2/">&laquo; __('prev')</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/4/">__('next') &raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/">C++</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GCC/">GCC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/I-O/">I/O</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/IDA-pro/">IDA pro</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/KVM/">KVM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ocaml/">Ocaml</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PID-namespace/">PID namespace</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/QEMU/">QEMU</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SGX/">SGX</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/binutils/">binutils</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/chrome/">chrome</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/container/">container</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/intel/">intel</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kvm/">kvm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux内核/">linux内核</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/llvm/">llvm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/memory/">memory</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/namespace/">namespace</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nginx/">nginx</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/php/">php</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/server/">server</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/shell/">shell</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/x64-assembly/">x64 assembly</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/x86-64/">x86-64</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/二进制/">二进制</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/内存安全/">内存安全</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/底层安全/">底层安全</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/操作系统/">操作系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/文件系统/">文件系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/浏览器安全/">浏览器安全</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/爬虫/">爬虫</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/硬件/">硬件</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/系统安全/">系统安全</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/编译器/">编译器</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/编译安全/">编译安全</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/虚函数/">虚函数</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/虚拟化/">虚拟化</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/链接器/">链接器</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/静态分析/">静态分析</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/C/" style="font-size: 10px;">C++</a> <a href="/tags/GCC/" style="font-size: 17.14px;">GCC</a> <a href="/tags/I-O/" style="font-size: 11.43px;">I/O</a> <a href="/tags/IDA-pro/" style="font-size: 10px;">IDA pro</a> <a href="/tags/KVM/" style="font-size: 10px;">KVM</a> <a href="/tags/Ocaml/" style="font-size: 11.43px;">Ocaml</a> <a href="/tags/PID-namespace/" style="font-size: 10px;">PID namespace</a> <a href="/tags/QEMU/" style="font-size: 10px;">QEMU</a> <a href="/tags/SGX/" style="font-size: 12.86px;">SGX</a> <a href="/tags/binutils/" style="font-size: 10px;">binutils</a> <a href="/tags/chrome/" style="font-size: 10px;">chrome</a> <a href="/tags/container/" style="font-size: 10px;">container</a> <a href="/tags/intel/" style="font-size: 11.43px;">intel</a> <a href="/tags/kvm/" style="font-size: 10px;">kvm</a> <a href="/tags/linux/" style="font-size: 20px;">linux</a> <a href="/tags/linux内核/" style="font-size: 12.86px;">linux内核</a> <a href="/tags/llvm/" style="font-size: 10px;">llvm</a> <a href="/tags/memory/" style="font-size: 10px;">memory</a> <a href="/tags/namespace/" style="font-size: 11.43px;">namespace</a> <a href="/tags/nginx/" style="font-size: 11.43px;">nginx</a> <a href="/tags/php/" style="font-size: 10px;">php</a> <a href="/tags/python/" style="font-size: 10px;">python</a> <a href="/tags/server/" style="font-size: 11.43px;">server</a> <a href="/tags/shell/" style="font-size: 10px;">shell</a> <a href="/tags/x64-assembly/" style="font-size: 11.43px;">x64 assembly</a> <a href="/tags/x86-64/" style="font-size: 10px;">x86-64</a> <a href="/tags/二进制/" style="font-size: 10px;">二进制</a> <a href="/tags/内存安全/" style="font-size: 10px;">内存安全</a> <a href="/tags/底层安全/" style="font-size: 10px;">底层安全</a> <a href="/tags/操作系统/" style="font-size: 18.57px;">操作系统</a> <a href="/tags/文件系统/" style="font-size: 10px;">文件系统</a> <a href="/tags/浏览器安全/" style="font-size: 10px;">浏览器安全</a> <a href="/tags/爬虫/" style="font-size: 10px;">爬虫</a> <a href="/tags/硬件/" style="font-size: 10px;">硬件</a> <a href="/tags/系统安全/" style="font-size: 12.86px;">系统安全</a> <a href="/tags/编译器/" style="font-size: 11.43px;">编译器</a> <a href="/tags/编译安全/" style="font-size: 15.71px;">编译安全</a> <a href="/tags/虚函数/" style="font-size: 10px;">虚函数</a> <a href="/tags/虚拟化/" style="font-size: 14.29px;">虚拟化</a> <a href="/tags/链接器/" style="font-size: 10px;">链接器</a> <a href="/tags/静态分析/" style="font-size: 12.86px;">静态分析</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">June 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">May 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">February 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">January 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">December 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">March 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">February 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/07/28/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2017/07/15/浅谈GCC编译优化/">浅谈GCC编译优化</a>
          </li>
        
          <li>
            <a href="/2017/06/27/虚函数，原理和攻击方式/">从虚函数的实现，到虚表劫持攻击</a>
          </li>
        
          <li>
            <a href="/2017/06/19/编译链中的一环，静态链接详解/">编译链中的一环，静态链接详解</a>
          </li>
        
          <li>
            <a href="/2017/06/09/Hack gcc：添加新的函数/">Hack GCC，在编译时构造新的函数</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>